{"cells": [{"cell_type": "markdown", "id": "b4997a0a", "metadata": {"tags": ["md", "learner", "learner_chopped"]}, "source": ["<hr style=\"height: 1px;\">\n", "<i>This notebook was authored by the 8.S50x Course Team, Copyright 2022 MIT All Rights Reserved.</i>\n", "<hr style=\"height: 1px;\">\n", "<br>\n", "\n", "<h1>Lesson 21: Monte Carlo II - Advances with AI</h1>"]}, {"cell_type": "markdown", "id": "100dd6f6", "metadata": {"tags": ["md", "learner", "learner_chopped"]}, "source": ["<a name='section_22_0'></a>\n", "<hr style=\"height: 1px;\">\n", "\n", "\n", "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\">L21.0 Overview</h2>\n"]}, {"cell_type": "markdown", "id": "d8d25e2e", "metadata": {"tags": ["md", "learner", "learner_chopped"]}, "source": ["<h3>Navigation</h3>\n", "\n", "<table style=\"width:100%\">\n", "    <tr>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#section_22_1\">L21.1 Variational Autoencoders for Monte Carlo based Event Generation</a></td>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#exercises_22_1\">L21.1 Exercises</a></td>\n", "    </tr>\n", "    <tr>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#section_22_2\">L21.2 Generating Bragg Scattering with Variational Autoencoders</a></td>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#exercises_22_2\">L21.2 Exercises</a></td>\n", "    </tr>\n", "    <tr>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#section_22_3\">L21.3 Generating Full Bragg Scattering Details</a></td>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#exercises_22_3\">L21.3 Exercises</a></td>\n", "    </tr>\n", "    <tr>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#section_22_4\">L21.4 Conditional VAEs Allowing for Energy Based Generation</a></td>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#exercises_22_4\">L21.4 Exercises</a></td>\n", "    </tr>\n", "    <tr>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#section_22_5\">L21.5 Bootstrapping</a></td>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#exercises_22_5\">L21.5 Exercises</a></td>\n", "    </tr>\n", "     <tr>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#section_22_6\">L21.6 Bootstrapping For Neural Networks</a></td>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\">No Exercises</td>\n", "    </tr>\n", "</table>"]}, {"cell_type": "markdown", "id": "951ee763", "metadata": {"tags": ["catsoop_00", "learner"]}, "source": ["<h3>Learning Objectives</h3>\n", "\n", "We continue our exploration of  Monte Carlo strategies, now adding Machine Learning, and show how some of the biggest advances in Artificial Intelligence are changing the way we simulate scientific data."]}, {"cell_type": "markdown", "id": "98f0708c", "metadata": {"tags": ["catsoop_00", "learner"]}, "source": ["<h3>Slides</h3>\n", "\n", "You can access the slides related to this lecture at the following link: <a href=\"https://github.com/mitx-8s50/slides/raw/main/module3_slides/L22_slides.pdf\" target=\"_blank\">L21 Slides</a>"]}, {"cell_type": "markdown", "id": "56766721", "metadata": {"tags": ["md", "learner"]}, "source": ["<h3>Data</h3>\n", "\n", "Download the directory where we will save data."]}, {"cell_type": "code", "execution_count": null, "id": "c4046d2f", "metadata": {"tags": ["learner", "py", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L21.0-runcell00\n", "\n", "!git init\n", "!git remote add -f origin https://github.com/mitx-8s50/nb_LEARNER/\n", "!git config core.sparseCheckout true\n", "!echo 'data/L22' >> .git/info/sparse-checkout\n", "!git pull origin main"]}, {"cell_type": "markdown", "id": "cb350d28", "metadata": {"tags": ["md", "learner"]}, "source": ["<h3>Installing Tools</h3>\n", "\n", "Before we do anything, let's install the tools we need. Note that these installations take a bit longer than usual."]}, {"cell_type": "code", "execution_count": null, "id": "7f843412", "metadata": {"tags": ["learner", "py", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L21.0-runcell01\n", "\n", "!pip install corner\n", "!pip install torchvision\n", "!pip install pylandau #from here: https://pypi.org/project/pylandau/\n", "!pip install git+https://github.com/SengerM/landaupy\n", "\n", "#from here: https://github.com/SengerM/landaupy\n", "#https://github.com/SengerM/landaupy/blob/main/LICENSE"]}, {"cell_type": "markdown", "id": "3bc80458", "metadata": {"tags": ["md", "learner"]}, "source": ["<h3>Importing Libraries</h3>\n", "\n", "Before beginning, run the cell below to import the relevant libraries for this notebook. "]}, {"cell_type": "code", "execution_count": null, "id": "92e910f7", "metadata": {"tags": ["py", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L21.0-runcell02\n", "\n", "import imageio\n", "from PIL import Image\n", "\n", "import numpy as np\n", "import torch\n", "import torch.nn as nn\n", "import matplotlib.pyplot as plt\n", "import csv\n", "import math\n", "from scipy import optimize as opt \n", "\n", "import pandas as pd \n", "import torchvision\n", "from torchvision import transforms\n", "from torch.utils.data import DataLoader,random_split\n", "import torch.nn.functional as F\n", "import torch.optim as optim\n", "import corner\n", "\n", "from landaupy import landau"]}, {"cell_type": "markdown", "id": "1edc15fe", "metadata": {"tags": ["md", "learner"]}, "source": ["<h3>Setting Default Figure Parameters</h3>\n", "\n", "The following code cell sets default values for figure parameters.\n"]}, {"cell_type": "code", "execution_count": null, "id": "6e40a219", "metadata": {"tags": ["py", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L21.0-runcell03\n", "\n", "#set plot resolution\n", "%config InlineBackend.figure_format = 'retina'\n", "\n", "#set default figure parameters\n", "plt.rcParams['figure.figsize'] = (9,6)\n", "\n", "medium_size = 12\n", "large_size = 15\n", "\n", "plt.rc('font', size=medium_size)          # default text sizes\n", "plt.rc('xtick', labelsize=medium_size)    # xtick labels\n", "plt.rc('ytick', labelsize=medium_size)    # ytick labels\n", "plt.rc('legend', fontsize=medium_size)    # legend\n", "plt.rc('axes', titlesize=large_size)      # axes title\n", "plt.rc('axes', labelsize=large_size)      # x and y labels\n", "plt.rc('figure', titlesize=large_size)    # figure title"]}, {"cell_type": "markdown", "id": "75155c5f", "metadata": {"tags": ["md", "learner", "learner_chopped"]}, "source": ["<a name='section_22_1'></a>\n", "<hr style=\"height: 1px;\">\n", "\n", "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\">L21.1 Variational Autoencoders for Monte Carlo based Event Generation</h2>  \n", "\n", "\n", "| [Top](#section_22_0) | [Previous Section](#section_22_0) | [Exercises](#exercises_22_1) | [Next Section](#section_22_2) |\n"]}, {"cell_type": "markdown", "id": "9f51af1b", "metadata": {"tags": ["learner"]}, "source": ["*The material in this section is discussed in the video **<a href=\"https://courses.mitxonline.mit.edu/learn/course/course-v1:MITxT+8.S50.3x+3T2023/block-v1:MITxT+8.S50.3x+3T2023+type@sequential+block@seq_LS21/block-v1:MITxT+8.S50.3x+3T2023+type@vertical+block@vert_LS21_vid1\" target=\"_blank\">HERE</a>.** You are encouraged to watch that video and use this notebook concurrently.*"]}, {"cell_type": "markdown", "id": "8c98d6d1", "metadata": {"tags": ["lect_01", "learner"]}, "source": ["<h3>Overview</h3>\n", "\n", "We will start by discussing \"variational autoencoders,\" which are popular for tasks such as generating new data samples, data imputation (i.e., replacing missing data), and representation learning (which is defined <a href=\"https://en.wikipedia.org/wiki/Feature_learning\">here</a>). They have been applied in various domains, including image generation, text generation, and drug discovery, among others.\n", "\n", "In short, variational autoencoders create a probabilistic mapping between the input data and a latent space, where each point in the latent space represents a probability distribution over possible inputs. This probabilistic approach allows VAEs to generate new data points similar to those in the input by sampling from the learned distributions."]}, {"cell_type": "markdown", "id": "3fe50dab", "metadata": {"tags": ["lect_01", "learner"]}, "source": ["Before we go down the path of using variational autoencoders for simulation, let's take a little bit of time to run one of the famous illustrative examples of variational autoencoders. I have to say, this specific example made me understand the advantage of using VAEs, and got me hooked on them.\n", "\n", "For this, we are going to use the MNIST character dataset, which was one of the first ML datasets. This dataset has become the basis for testing and validating deep learning algorithms. It is so deeply embedded into the `pytorch` library that we can just load it from there. The following code cell does that and also configures the dataset to be used for training.\n"]}, {"cell_type": "code", "execution_count": null, "id": "b8228e0d", "metadata": {"tags": ["lect_01", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L21.1-runcell01\n", "\n", "# Set random seed for reproducibility\n", "torch.manual_seed(0)\n", "\n", "data_dir = 'data/L22/dataset'\n", "\n", "train_dataset = torchvision.datasets.MNIST(data_dir, train=True, download=True)\n", "test_dataset  = torchvision.datasets.MNIST(data_dir, train=False, download=True)\n", "\n", "train_transform = transforms.Compose([transforms.ToTensor(),])\n", "\n", "test_transform = transforms.Compose([transforms.ToTensor(),])\n", "\n", "train_dataset.transform = train_transform\n", "test_dataset.transform = test_transform\n", "\n", "m=len(train_dataset)\n", "\n", "train_data, val_data = random_split(train_dataset, [int(m-m*0.2), int(m*0.2)])\n", "batch_size=256\n", "\n", "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size)\n", "valid_loader = torch.utils.data.DataLoader(val_data, batch_size=batch_size)\n", "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size,shuffle=True)\n", "\n", "#train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n", "#valid_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False)\n", "#test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"]}, {"cell_type": "markdown", "id": "9e48ff3b", "metadata": {"tags": ["lect_01", "learner"]}, "source": ["Now, we need to define the neural network architecture. While this is not the focus of this lecture, let's take a few minutes to look at how we encode this.\n", "\n", "For this architecture we are going to take the MNIST input dataset, and encode it into a large vector. The past 10 years of research on deep learning has shown that Convolutional Neural Networks (CNNs) are one of the most robust ways to encode images. Our encoder will thus be 3 convolutional NN layers stringed together. Each one produces a smaller image from the previous image. Once the image is small enough (3x3, but with 32 features), we take the image and linearize it to a single vector, which we then feed into normal Dense(Linear) layers.\n", "\n", "Finally, because this is a variational autoencoder, we need to output a mean and a sigma for each dimension in the latent space. Once we have the mean and the sigma, we can randomly sample a normal distribution with these features. "]}, {"cell_type": "code", "execution_count": null, "id": "02692699", "metadata": {"tags": ["lect_01", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L21.1-runcell02\n", "\n", "class VariationalEncoder(nn.Module):\n", "    def __init__(self, latent_dims):  \n", "        super(VariationalEncoder, self).__init__()\n", "        self.conv1 = nn.Conv2d(1, 8, 3, stride=2, padding=1)\n", "        self.conv2 = nn.Conv2d(8, 16, 3, stride=2, padding=1)\n", "        self.batch2 = nn.BatchNorm2d(16)\n", "        self.conv3 = nn.Conv2d(16, 32, 3, stride=2, padding=0)  \n", "        self.linear1 = nn.Linear(3*3*32, 128)\n", "        self.linear2 = nn.Linear(128, latent_dims)\n", "        self.linear3 = nn.Linear(128, latent_dims)\n", "\n", "        #Now we need sample in phase space \n", "        self.N       = torch.distributions.Normal(0, 1)\n", "        self.N.loc   = self.N.loc \n", "        self.N.scale = self.N.scale\n", "        self.kl = 0\n", "\n", "    def forward(self, x):\n", "        #print(x.shape)\n", "        x = F.relu(self.conv1(x))\n", "        x = F.relu(self.batch2(self.conv2(x)))\n", "        x = F.relu(self.conv3(x))\n", "        x = torch.flatten(x, start_dim=1)\n", "        x = F.relu(self.linear1(x))\n", "        mu =  self.linear2(x) #Mean in the gaussian space\n", "        sigma = torch.exp(self.linear3(x)) #sigma in the space\n", "        z = mu + sigma*self.N.sample(mu.shape) #smear \n", "        self.kl = (sigma**2 + mu**2 - torch.log(sigma) - 1/2).sum() #Now compute the KL divergence\n", "        return z      "]}, {"cell_type": "markdown", "id": "7daa4352", "metadata": {"tags": ["lect_01", "learner"]}, "source": ["Now that we have encoded everything in a space, we can go ahead and decode it so that we can build a network that tries to generate the original image from the lower dimensional intermediate space. This decoder is the inverse of the encoder. It starts from the vector in the latent space and then expands out the image using the inverse of CNNs, namely `ConvTranspose2d`, which generates an image from a vector. Below is our decoder, which finally yields an image at the end.\n"]}, {"cell_type": "code", "execution_count": null, "id": "b2374b20", "metadata": {"tags": ["lect_01", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L21.1-runcell03\n", "\n", "class Decoder(nn.Module):\n", "    \n", "    def __init__(self, latent_dims):\n", "        super().__init__()\n", "\n", "        self.decoder_lin = nn.Sequential(\n", "            nn.Linear(latent_dims, 128),\n", "            nn.ReLU(True),\n", "            nn.Linear(128, 3 * 3 * 32),\n", "            nn.ReLU(True)\n", "        )\n", "\n", "        self.unflatten = nn.Unflatten(dim=1, unflattened_size=(32, 3, 3))\n", "\n", "        self.decoder_conv = nn.Sequential(\n", "            nn.ConvTranspose2d(32, 16, 3, stride=2, output_padding=0),\n", "            nn.BatchNorm2d(16),\n", "            nn.ReLU(True),\n", "            nn.ConvTranspose2d(16, 8, 3, stride=2, padding=1, output_padding=1),\n", "            nn.BatchNorm2d(8),\n", "            nn.ReLU(True),\n", "            nn.ConvTranspose2d(8, 1, 3, stride=2, padding=1, output_padding=1)\n", "        )\n", "        \n", "    def forward(self, x):\n", "        x = self.decoder_lin(x)\n", "        x = self.unflatten(x)\n", "        x = self.decoder_conv(x)\n", "        x = torch.sigmoid(x)\n", "        return x"]}, {"cell_type": "markdown", "id": "1b67d234", "metadata": {"tags": ["lect_01", "learner"]}, "source": ["Finally, we can go ahead and combine everything together to make our variational autoencoder. One last element that we need to understand is how we train this NN. The way we do this is to check how close the outputs are to being equal to the inputs. We accomplish this in the usual way by defining a loss function $\\mathcal{L}$ and then minimizing it. Given inputs $x_{i}$ and outputs $y_{i}$ each of size $N$, we can write:\n", "\n", "$$\n", "\\mathcal{L} = \\sum^{N}_{i} (x_{i}-y_{i})^{2}\n", "$$\n", "\n", "Now, from studies of the variational autoencoder using this loss definition, we find we need to add an additional term. It is referred to as the Kullback-Liebler(KL) divergence term for the latent space to approximate a Gaussian.\n", "\n", "What does this mean?\n", "\n", "The KL divergence is a measure of how similar two probability distributions are to each other. For two probability distributions $p(x)$ and $q(x)$, it is defined as:\n", "\n", "$$\n", "\\mathcal{D}_{\\rm KL}\\left(P||Q\\right)  = \\int_{-\\infty}^{\\infty} p(x) \\log\\left(\\frac{p(x)}{q(x)}\\right) dx\n", "$$\n", "\n", "It is effectively the difference in log probabilities of two distributions (or some notion of the <a href=\"https://en.wikipedia.org/wiki/Entropy_(information_theory)\" target=\"_blank\">entropy</a>). In the case of the VAE, we apply a KL divergence for the probability distribution of the latent space to approximate a Gaussian distribution with width 1, i.e.: $f(x) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} e^{-\\frac{(x - \\mu)^2}{2\\sigma^2}}$\n", "\n", "\n", "This we can write as:\n", "\n", "$$\n", "\\log\\left(\\mathcal{N}(\\mu,\\sigma)\\right) = -\\frac{1}{2}\\log\\left(2\\pi\\sigma^{2}\\right)-\\left(\\frac{x-\\mu}{2\\sigma}\\right)^{2} \\\\\n", "\\log\\left(\\mathcal{N}(\\mu,\\sigma)\\right) - \\log\\left(\\mathcal{N}(\\mu=0,\\sigma=1)\\right) =\n", "-\\frac{1}{2}\\log\\left(2\\pi\\sigma^{2}\\right)-\\left(\\frac{x-\\mu}{2\\sigma}\\right)^{2}+\\frac{1}{2}\\log\\left(2\\pi\\right)+\\frac{x^2}{2}\\\\\n", "$$\n", "\n", "Now we determine $\\mathcal{D}_{\\rm KL}\\left(P||Q\\right)$:\n", "\n", "$$\n", "\\int_{-\\infty}^{\\infty} p(x) \\log\\left(\\frac{p(x)}{q(x)}\\right) dx =\n", "-\\frac{1}{2}\\log\\left(\\sigma^{2}\\right) - \\frac{1}{4}  + \\frac{\\sigma^2}{2} + \\frac{\\mu^2}{2}\n", "\\\\\n", "\\mathcal{D}_{\\rm KL}\\left(\\mathcal{N}(\\mu,\\sigma)||\\mathcal{N}(\\mu=0,\\sigma=1)\\right) =\n", "-\\frac{1}{2}\\log\\left(\\sigma^{2}\\right) - \\frac{1}{4}  + \\frac{\\sigma^2}{2} + \\frac{\\mu^2}{2}\n", "$$\n"]}, {"cell_type": "code", "execution_count": null, "id": "f0845a7e", "metadata": {"tags": ["lect_01", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L21.1-runcell04\n", "\n", "class VariationalAutoencoder(nn.Module):\n", "    def __init__(self, latent_dims):\n", "        super(VariationalAutoencoder, self).__init__()\n", "        self.encoder = VariationalEncoder(latent_dims)\n", "        self.decoder = Decoder(latent_dims)\n", "        self.kl      = 0\n", "        \n", "    def forward(self, x):\n", "        z = self.encoder(x)\n", "        kl = self.encoder.kl\n", "        return self.decoder(z)"]}, {"cell_type": "markdown", "id": "39b0a9e2", "metadata": {"tags": ["lect_01", "learner"]}, "source": ["Now, let's train this and embed it into 2 latent dimensions! With that, we can see what is going on. Note that `L21.1-runcell06` takes a considerable time to run. Watching the results of each epoch, you can clearly see the output images getting closer and closer in appearance to the inputs, although the improvement slows down for the later epochs."]}, {"cell_type": "code", "execution_count": null, "id": "9587c9f9", "metadata": {"tags": ["lect_01", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L21.1-runcell05\n", "\n", "### Set the random seed for reproducible results\n", "### If restarting the training, must run this part again\n", "torch.manual_seed(0)\n", "d = 2\n", "vae = VariationalAutoencoder(latent_dims=d)\n", "lr = 1e-3 \n", "optim = torch.optim.Adam(vae.parameters(), lr=lr, weight_decay=1e-5)\n", "\n", "### Training function\n", "def train_epoch(vae, dataloader, optimizer):\n", "    # Set train mode for both the encoder and the decoder\n", "    vae.train()\n", "    train_loss = 0.0\n", "    # Iterate the dataloader (we do not need the label values, this is unsupervised learning)\n", "    for x, _ in dataloader: \n", "        # Move tensor to the proper device\n", "        x_hat = vae(x)\n", "        # Evaluate loss\n", "        loss = ((x - x_hat)**2).sum() + vae.kl\n", "        # Backward pass\n", "        optimizer.zero_grad()\n", "        loss.backward()\n", "        optimizer.step()\n", "        # Print batch loss\n", "        #print('\\t partial train loss (single batch): %f' % (loss.item()))\n", "        train_loss+=loss.item()\n", "\n", "    return train_loss / len(dataloader.dataset)\n", "\n", "### Testing function\n", "def test_epoch(vae, dataloader):\n", "    # Set evaluation mode for encoder and decoder\n", "    vae.eval()\n", "    val_loss = 0.0\n", "    with torch.no_grad(): # No need to track the gradients\n", "        for x, _ in dataloader:\n", "            # Encode data\n", "            encoded_data = vae.encoder(x)\n", "            # Decode data\n", "            x_hat = vae(x)\n", "            loss = ((x - x_hat)**2).sum() + vae.kl\n", "            val_loss += loss.item()\n", "\n", "    return val_loss / len(dataloader.dataset)\n", "\n", "def plot_ae_outputs(encoder,decoder,n=10):\n", "    plt.figure(figsize=(16,4.5))\n", "    targets = test_dataset.targets.numpy()\n", "    t_idx = {i:np.where(targets==i)[0][0] for i in range(n)}\n", "    for i in range(n):\n", "      ax = plt.subplot(2,n,i+1)\n", "      img = test_dataset[t_idx[i]][0].unsqueeze(0)\n", "      encoder.eval()\n", "      decoder.eval()\n", "      with torch.no_grad():\n", "         rec_img  = decoder(encoder(img))\n", "      plt.imshow(img.cpu().squeeze().numpy(), cmap='gist_gray')\n", "      ax.get_xaxis().set_visible(False)\n", "      ax.get_yaxis().set_visible(False)  \n", "      if i == n//2:\n", "        ax.set_title('Original images')\n", "      ax = plt.subplot(2, n, i + 1 + n)\n", "      plt.imshow(rec_img.cpu().squeeze().numpy(), cmap='gist_gray')  \n", "      ax.get_xaxis().set_visible(False)\n", "      ax.get_yaxis().set_visible(False)  \n", "      if i == n//2:\n", "         ax.set_title('Reconstructed images')\n", "    plt.show()  "]}, {"cell_type": "code", "execution_count": null, "id": "0b5de372", "metadata": {"tags": ["lect_01", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L21.1-runcell06\n", "\n", "### NOTE: If restarting the training, must run lines below\n", "\"\"\"\n", "torch.manual_seed(0)\n", "d = 2\n", "vae = VariationalAutoencoder(latent_dims=d)\n", "lr = 1e-3 \n", "optim = torch.optim.Adam(vae.parameters(), lr=lr, weight_decay=1e-5)\n", "\"\"\"\n", "\n", "num_epochs = 10\n", "\n", "for epoch in range(num_epochs):\n", "    train_loss = train_epoch(vae,train_loader,optim)\n", "    val_loss = test_epoch(vae,valid_loader)\n", "    print('\\n EPOCH {}/{} \\t train loss {:.3f} \\t val loss {:.3f}'.format(epoch + 1, num_epochs,train_loss,val_loss))\n", "    plot_ae_outputs(vae.encoder,vae.decoder,n=10)"]}, {"cell_type": "markdown", "id": "756bc435", "metadata": {"tags": ["lect_01", "learner"]}, "source": ["Note the surprising feature that the reconstruction of the `8` gets worse starting with epoch 6 and never recovers. Also, the reconstruction of the oddly written `5` converges on something totally wrong and the reconstruction of the `3` appears to deteriorate towards the end. This is likely because the dimension of the latent space is too small.\n", "\n", "\n", "Now, let's visualize what this looks like in the latent space. This tells us a lot about what we are learning. What we will see is a 2D space of numbers in the VAE that the images are embedded into. In order to create an output, the VAE samples this `x` and `y` coordinate about the projection and tries to reproduce the input. Note, the space is continuous, and we have just chosen to plot a discrete set of images in the space."]}, {"cell_type": "code", "execution_count": null, "id": "5fcd63b7", "metadata": {"tags": ["lect_01", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L21.1-runcell07\n", "\n", "def plot_reconstructed(autoencoder, r0=(-2, 2), r1=(-2, 2), n=12):\n", "    w = 28\n", "    img = np.zeros((n*w, n*w))\n", "    for i, y in enumerate(np.linspace(*r1, n)):\n", "        for j, x in enumerate(np.linspace(*r0, n)):\n", "            z = torch.Tensor([[x, y]])\n", "            x_hat = autoencoder.decoder(z)\n", "            x_hat = x_hat.reshape(28, 28).to('cpu').detach().numpy()\n", "            img[(n-1-i)*w:(n-1-i+1)*w, j*w:(j+1)*w] = x_hat\n", "    plt.imshow(img, extent=[*r0, *r1])\n", "    \n", "plot_reconstructed(vae)"]}, {"cell_type": "markdown", "id": "35afb9d8", "metadata": {"tags": ["md", "learner", "learner_chopped"]}, "source": ["<a name='exercises_22_1'></a>     \n", "\n", "| [Top](#section_22_0) | [Restart Section](#section_22_1) | [Next Section](#section_22_2) |\n"]}, {"cell_type": "markdown", "id": "6ad682d8", "metadata": {"tags": ["md", "learner", "learner_chopped"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Exercise 21.1.1</span>\n", "\n", "What is the primary function of the latent space in a Variational Autoencoder (VAE)?\n", "\n", "A) To provide a discrete set of vectors that uniquely represent all possible input data.\\\n", "B) To serve as a lower-dimensional, continuous representation of the input data, capturing its essential features.\\\n", "C) To act as a set of orthogonal vectors used to span the vector space of the input data.\\\n", "D) To directly output the reconstructed data from the input.\n", "\n", "<br>"]}, {"cell_type": "markdown", "id": "f549b9df", "metadata": {"tags": ["md", "learner", "learner_chopped"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Exercise 21.1.2</span>\n", "\n", "When comparing the inputs with the outputs found by sampling the results of the training, we see that it still has difficulty reproducing some numbers (in particular the 3 and 8, although admittedly that's a very odd looking 5). What can we do to make it better? Select ALL that apply, then try all of these for yourself!\n", "\n", "A) Decrease the latent space dimension\\\n", "B) Increase the latent space dimension\\\n", "C) Decrease the number of training epochs\\\n", "D) Increase the number of training epochs\\\n", "E) Decrease the standard deviation\\\n", "F) Increase the standard deviation\n", "\n", "\n", "<br>"]}, {"cell_type": "markdown", "id": "1568a6cb", "metadata": {"tags": ["md", "learner", "learner_chopped"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Exercise 21.1.3</span>\n", "\n", "Adjust the code in `L21.1-runcell05` (or the commented section in `L21.1-runcell06`) to use a 3-dimensional latent space. How does this change the training and validation losses after 10 epochs, compared to using 2 dimensions? Report both numbers after 10 epochs, as a list `[train_loss, val_loss]` with single-digit precision.\n", "\n", "\n", "<br>"]}, {"cell_type": "markdown", "id": "1f3bdac7", "metadata": {"tags": ["md", "learner", "learner_chopped"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Exercise 21.1.4</span>\n", "\n", "\n", "Why are variational autoencoders better or more flexible than regular autoencoders? Select ALL that apply:\n", "\n", "A) VAEs model the latent space as a probability distribution, which allows VAEs to generate new data points by sampling from the learned latent space.\n", "\n", "B) VAEs force the latent space to be continuous and smooth, which facilitates meaningful interpolations between data points in the latent space.\n", "\n", "C) VAEs allow for more flexibility in designing the latent space, such as controlling the dimensionality and imposing specific distributional assumptions (e.g., Gaussian distribution).\n", "\n", "\n", "<br>"]}, {"cell_type": "markdown", "id": "949f706a", "metadata": {"tags": ["md", "learner", "learner_chopped"]}, "source": ["<a name='section_22_2'></a>\n", "<hr style=\"height: 1px;\">\n", "\n", "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\">L21.2 Generating Bragg Scattering with Variational Autoencoders </h2>  \n", "\n", "| [Top](#section_22_0) | [Previous Section](#section_22_1) | [Exercises](#exercises_22_2) | [Next Section](#section_22_3) |"]}, {"cell_type": "markdown", "id": "16458b57", "metadata": {"tags": ["learner"]}, "source": ["*The material in this section is discussed in the video **<a href=\"https://courses.mitxonline.mit.edu/learn/course/course-v1:MITxT+8.S50.3x+3T2023/block-v1:MITxT+8.S50.3x+3T2023+type@sequential+block@seq_LS21/block-v1:MITxT+8.S50.3x+3T2023+type@vertical+block@vert_LS21_vid2\" target=\"_blank\">HERE</a>.** You are encouraged to watch that video and use this notebook concurrently.*"]}, {"cell_type": "markdown", "id": "4b9ed021", "metadata": {"tags": ["lect_02", "learner"]}, "source": ["<h3>Overview</h3>\n", "\n", "Now, we will build a variational autoencoder to model Bragg Scattering. Additionally, we will try to predict the values of a few specific parameters:\n", "\n", " * Beam Width\n", " * Beam Length\n", " * Energy deposited in the last centimeter\n", " * Energy deposited in the first centimeter\n", "\n", "Let's go ahead and construct this guy! We can do this one of two ways, either (1) load the functions and create the data that we used previously, or (2) load some premade data from our repository (created using the same code).\n", "\n", "Note that (1) will take a while, mostly because, as mentioned in a previous Lesson, the Landau sampling cannot be parallelized. If you want to go this route, then uncomment the code and run `L21.2-runcell01`. It's good to know where the data comes from, and this is step is shown in the related video.\n", "\n", "However, if you want to save time, then skip to cell `L21.2-runcell02` and load the data there."]}, {"cell_type": "code", "execution_count": null, "id": "ff9f8954", "metadata": {"tags": ["lect_02", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L21.2-runcell01\n", "\n", "import pylandau\n", "from landaupy import landau\n", "\n", "#values\n", "def I(iZ,iPlot=False):\n", "    #https://github.com/nrc-cnrc/EGSnrc/blob/master/HEN_HOUSE/pegs4/pegs4.mortran#L1354-L1391\n", "    lI=[19.2,41.8,40.,63.7,76.0,78.0,82.0,95.0,115.,137.,\n", "     149.,156.,166.,173.,173.,180.,174.,188.,190.,191.,216.,233.,245.,\n", "     257.,272.,286.,297.,311.,322.,330.,334.,350.,347.,348.,357.,352.,\n", "     363.,366.,379.,393.,417.,424.,428.,441.,449.,470.,470.,469.,488.,\n", "     488.,487.,485.,491.,482.,488.,491.,501.,523.,535.,546.,560.,574.,\n", "     580.,591.,614.,628.,650.,658.,674.,684.,694.,705.,718.,727.,736.,\n", "     746.,757.,790.,790.,800.,810.,823.,823.,830.,825.,794.,827.,826.,\n", "     841.,847.,878.,890.,902.,921.,934.,939.,952.,966.,980.,994.]\n", "    lZ=np.arange(1,len(lI)+1)\n", "    if iPlot:\n", "        plt.plot(lZ,lI/lZ)\n", "        plt.xlabel('Z')\n", "        plt.ylabel('I$_{adj}$/Z (eV/Z)')\n", "        plt.show()\n", "    return lI[iZ]*1e-6 #MeV not eV\n", "\n", "def A(iZ,iPlot=False):\n", "    #https://github.com/nrc-cnrc/EGSnrc/blob/master/HEN_HOUSE/pegs4/pegs4.mortran#L1354-L1391\n", "    lA=[1.00797,4.0026,6.939,9.0122,10.811,12.01115,14.0067,\n", "     15.9994,18.9984,20.183,22.9898,24.312,26.9815,28.088,30.9738,\n", "     32.064,35.453,39.948,39.102,40.08,44.956,47.90,50.942,51.998,\n", "     54.9380,55.847,58.9332,58.71,63.54,65.37,69.72,72.59,74.9216,\n", "     78.96,79.808,83.80,85.47,87.62,88.905,91.22,92.906,95.94,99.0,\n", "     101.07,102.905,106.4,107.87,112.4,114.82,118.69,121.75,127.60,\n", "     126.9044,131.30,132.905,137.34,138.91,\n", "     140.12,140.907,144.24,147.,150.35,151.98,157.25,158.924,162.50,\n", "     164.930,167.26,168.934,173.04,174.97,178.49,180.948,183.85,\n", "     186.2,190.2,192.2,195.08,196.987,200.59,204.37,207.19,208.980,\n", "     210.,210.,222.,223.,226.,227.,232.036,231.,238.03,237.,242.,\n", "     243.,247.,247.,248.,254.,253.   \n", "    ]\n", "    lZ=np.arange(1,len(lA)+1)\n", "    if iPlot:\n", "        plt.plot(lZ,lA/lZ)\n", "        plt.xlabel('Z')\n", "        plt.ylabel('A/Z (Atomic mass/Z)')\n", "        plt.show()\n", "    return lA[iZ-1]\n", "\n", "\n", "m_e = 0.511 # Mass of electron in MeV\n", "\n", "def gamma(ip,im): #E^2=gamma^2m^2=p^2+m^2\n", "    return np.sqrt(1+(ip/im)**2)\n", "\n", "def beta(ip,im): #gamma=1/sqrt(1-b^2)\n", "    g=gamma(ip,im)\n", "    return np.sqrt(1-1./g**2)\n", "\n", "def betagamma(ip,im):#p=bgm\n", "    return ip/im\n", "\n", "def Tmax(ip,im): # Maximum energy transfer in one collision in MeV\n", "    return 2*m_e*(ip/im)**2/(1+2*gamma(ip,im)*m_e/im+(m_e/im)**2)\n", "\n", "def TKinheavy(ip,im): #(T+M)^2=sqrt(p)+sqrt(m)\n", "    return np.sqrt(np.sqrt(ip)+np.sqrt(um))-im\n", "\n", "def delta(ip,im):\n", "    C = 4.44\n", "    a = 0.1492\n", "    m = 3.25\n", "    X1 = 2.87\n", "    X0 = 0.2014\n", "    delta0 = 0.14\n", "    x = np.log10(ip/im)\n", "    #f1 = lambda x: delta0 * 10**(2*(x-X0)) # conductors pdg\n", "    f2 = 2 * x * np.log(10) - C + (a * np.maximum(0, (X1 - x))**m) #using np.maximum to prevent warning when x > X1\n", "    f3 = 2 * x * np.log(10) - C\n", "    delta_full = np.where(x < X0 , 0, f2)\n", "    delta_full = np.where(x < X1, delta_full, f3)\n", "    return delta_full\n", "        \n", "def dEdxF(ip,im,iZ,zpart=1,rho=1.0,nodelta=False): #Bethe-Bloch equation\n", "    K = 0.307075 # constant K in MeV cm mol^-1\n", "    #rho = 2.336 # Density of material in g cm^-3 (here: silicon density)\n", "    const   = zpart**2 * (K * rho * iZ ) / (2 * A(iZ)) * (1./beta(ip,im)**2)\n", "    logterm = 2 * m_e * Tmax(ip,im) * ((ip/im)**2)/(I(iZ)**2) \n", "    dEdxV   =  const * (np.log(logterm)  - 2*(beta(ip,im))**2 - delta(ip,im))              \n", "    if nodelta:\n", "        print(\"delta:\",delta(ip,im),dEdxV)\n", "        dEdxV    =  const * (np.log(logterm) - 2*(beta(ip,im))**2)\n", "    return dEdxV\n", "    \n", "mproton=938\n", "mpion=135.4\n", "mmuon=105.4\n", "\n", "def X0(iZ):\n", "    const=(716.408**-1)/A(iZ)\n", "    a = iZ/137.\n", "    Lrad =np.log(184.15*iZ**(-1./3.))\n", "    Lradp=np.log(1194*iZ**(-2./3.))\n", "    fZ = a**2*((1+a**2)**(-1)+0.20206-0.0369*a**2+0.0083*a**4-0.002*a**6)\n", "    val=const*(iZ**2*(Lrad-fZ)+iZ*Lradp)\n", "    return 1./val\n", "\n", "def sigmaTheta(ip,im,iX0,idx=1.0,zpart=1):\n", "    C=13.6\n", "    X0=iX0\n", "    dx=idx/iX0\n", "    const=C/(beta(ip,im)*ip)*zpart*np.sqrt(dx)\n", "    logterm=1+0.038*np.log(dx*zpart**2/beta(ip,im)**2)\n", "    return const*logterm\n", "\n", "def thetaScatter(ip,im,iX0,idx,zpart=1):\n", "    z1=np.random.normal(0,1,ip.shape[0])\n", "    z2=np.random.normal(0,1,ip.shape[0])\n", "    stheta=sigmaTheta(ip,im,iX0,zpart)\n", "    dy    =z1*idx*stheta/np.sqrt(12.) + z2*idx*stheta/2 \n", "    dtheta=z2*stheta\n", "    return dtheta,dy\n", "    \n", "def eToP(iE,im):\n", "    return np.sqrt((iE+im)**2-im**2)\n", "\n", "def landauMPV(ip,im,iZ,irho=1,zpart=1):\n", "    K = 0.307075 # constant K in MeV cm mol^-1\n", "    const   = zpart**2 * (K * irho * iZ ) / (2 * A(iZ)) * (1./beta(ip,im)**2)\n", "    #logterm  = 2 * m_e * Tmax(ip,im) * ((ip/im)**2)/(I(iZ)**2) \n", "    logterm1 = 2 * m_e *               ((ip/im)**2)/(I(iZ)) \n", "    logterm2 = const/I(iZ)\n", "    dEdxV    =  const * (np.log(logterm1) + np.log(logterm2) + 0.2     - (beta(ip,im))**2 - delta(ip,im))       # \n", "    return dEdxV,const\n", "\n", "\n", "def simNYParallelSample(iN, ie=500,im=935,idt=1e-10,iZ=8):\n", "    xstep  = np.empty((0,iN))\n", "    ystep  = np.empty((0,iN))\n", "    estep  = np.empty((0,iN))\n", "    pstep  = np.empty((0,iN))\n", "    theta=0\n", "    y=0\n", "    c=3e10\n", "    dist=np.zeros(iN)\n", "    e=np.ones(iN)*ie\n", "    lX0 = X0(iZ)\n", "    print(\"Scanning:\",ie)\n", "    while np.any(e > 5):\n", "        p = eToP(e,im)\n", "        lMPV,lWMPV  = landauMPV(p,im,iZ=iZ,irho=1.06)\n", "        dE = np.zeros(lMPV.shape)\n", "        ##Here we have to parallelize by hand, this is not good\n", "        for i0, (pMPV,pWMPV) in enumerate(zip(lMPV,lWMPV)):\n", "            dE[i0]     = landau.sample(pMPV, pWMPV,1)\n", "        dx     = beta(p,im)*c*idt#speed of light\n", "        dTheta,dy = thetaScatter(p,im,lX0,idx=dx,zpart=1)\n", "        pdEdX  = np.minimum(dE*dx,e-0.1)\n", "        e      -= pdEdX\n", "        dist   += dx*np.cos(theta)\n", "        y      += dy + np.sin(theta)*dx\n", "        theta  += dTheta\n", "        xstep  = np.vstack((xstep,dist))\n", "        ystep  = np.vstack((ystep,y))\n", "        estep  = np.vstack((estep,pdEdX))\n", "        pstep  = np.vstack((pstep,e))        \n", "    xstep = xstep.T\n", "    estep = estep.T\n", "    pstep = pstep.T\n", "    ystep = ystep.T\n", "    return xstep,pstep,estep,ystep\n", "\n", "#uncomment and run the simulation to generate the data, if desired\n", "\"\"\"\n", "xstep150,pstep150,estep150,ystep150=simNYParallelSample(ie=150,im=mproton,iN=1000,idt=1e-10,iZ=8)\n", "xstep200,pstep200,estep200,ystep200=simNYParallelSample(ie=200,im=mproton,iN=1000,idt=1e-10,iZ=8)\n", "xstep250,pstep250,estep250,ystep250=simNYParallelSample(ie=250,im=mproton,iN=1000,idt=1e-10,iZ=8)\n", "xstep300,pstep300,estep300,ystep300=simNYParallelSample(ie=300,im=mproton,iN=1000,idt=1e-10,iZ=8)\n", "\"\"\""]}, {"cell_type": "code", "execution_count": null, "id": "cb815828", "metadata": {"tags": ["lect_02", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L21.2-runcell02\n", "\n", "#load the data from the repository (equivalent to running the simulation above)\n", "\n", "#energy 150\n", "xstep150 = np.load('data/L22/xstep150.npy')\n", "pstep150 = np.load('data/L22/pstep150.npy')\n", "estep150 = np.load('data/L22/estep150.npy')\n", "ystep150 = np.load('data/L22/ystep150.npy')\n", "\n", "#energy 200\n", "xstep200 = np.load('data/L22/xstep200.npy')\n", "pstep200 = np.load('data/L22/pstep200.npy')\n", "estep200 = np.load('data/L22/estep200.npy')\n", "ystep200 = np.load('data/L22/ystep200.npy')\n", "\n", "#energy 250\n", "xstep250 = np.load('data/L22/xstep250.npy')\n", "pstep250 = np.load('data/L22/pstep250.npy')\n", "estep250 = np.load('data/L22/estep250.npy')\n", "ystep250 = np.load('data/L22/ystep250.npy')\n", "\n", "#energy 300\n", "xstep300 = np.load('data/L22/xstep300.npy')\n", "pstep300 = np.load('data/L22/pstep300.npy')\n", "estep300 = np.load('data/L22/estep300.npy')\n", "ystep300 = np.load('data/L22/ystep300.npy')"]}, {"cell_type": "markdown", "id": "48ebbef8", "metadata": {"tags": ["lect_02", "learner"]}, "source": ["Now that we have the dataset, lets go ahead and build some observables. To start with we are going to look at the energy in the first 3 cm, the energy in the last cm of the particle shower, and the final length and width of the shower. Lets go ahead and compute these off the showers we made. Note that the shower info we have saved is just a 2D image of the energy deosit of the particle in an x-y grid. "]}, {"cell_type": "code", "execution_count": null, "id": "57498cc3", "metadata": {"tags": ["lect_02", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L21.2-runcell03\n", "\n", "import torch\n", "import torch.nn as nn\n", "from torch.utils.data import Dataset\n", "from torch.autograd import Variable\n", "\n", "def sumEstep(estep,xstep):\n", "    efront=np.zeros(xstep.shape[0])\n", "    eback =np.zeros(xstep.shape[0])\n", "    for i0 in range(xstep.shape[0]):\n", "        efront[i0] = np.sum(estep[i0,xstep[i0] < 3])/3.\n", "        #print(xstep[i0] < 3,xstep[i0] > xstep[i0,-1]-3,xstep[i0,-1]-3,xstep[i0],estep[i0])\n", "        eback[i0]  = np.sum(estep[i0,xstep[i0] > xstep[i0,-1]-3])/3.\n", "    return efront,eback\n", "\n", "def createData(ixstep,ipstep,iestep,iystep):\n", "    length=ixstep[:,-1]\n", "    width =iystep[:,-1]\n", "    efront=np.zeros(ixstep.shape[0])\n", "    eback =np.zeros(ixstep.shape[0])\n", "    for i0 in range(ixstep.shape[0]):\n", "        efront[i0] = np.sum(iestep[i0,ixstep[i0] < 3])/3.\n", "        eback[i0]  = np.sum(iestep[i0,ixstep[i0] > ixstep[i0,-1]-1])\n", "    processed_data = np.vstack((length,width,efront,eback))\n", "    trainset       = torch.tensor(processed_data).float()\n", "    return trainset\n", "\n", "indataset150=createData(xstep150,pstep150,estep150,ystep150)\n", "indataset150=indataset150.T\n", "\n", "indataset200=createData(xstep200,pstep200,estep200,ystep200)\n", "indataset200=indataset200.T\n", "\n", "indataset250=createData(xstep250,pstep250,estep250,ystep250)\n", "indataset250=indataset250.T\n", "\n", "indataset300=createData(xstep300,pstep300,estep300,ystep300)\n", "indataset300=indataset300.T\n", "\n", "indataset   = np.vstack((indataset150,indataset200,indataset250,indataset300))\n", "print(indataset.shape)"]}, {"cell_type": "markdown", "id": "3381ff68", "metadata": {"tags": ["lect_02", "learner"]}, "source": ["Lastly, to make our code pytroch friendly, we need to define a pytorch dataset. This we do by making a pytorch class that can process our info. "]}, {"cell_type": "code", "execution_count": null, "id": "73f90ee8", "metadata": {"tags": ["lect_02", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L21.2-runcell04\n", "\n", "class DataSet(Dataset):\n", "    def __init__(self, samples, labels):\n", "        self.labels  = labels\n", "        self.samples = samples\n", "        if len(samples) != len(labels):\n", "            raise ValueError(\n", "                f\"should have the same number of samples({len(samples)}) as there are labels({len(labels)})\")\n", "\n", "    def __len__(self):\n", "        return len(self.labels)\n", "\n", "    def nfeatures(self):\n", "        return self.samples.shape[1]\n", "    \n", "    def __getitem__(self, index):\n", "        y = self.labels[index]\n", "        x = self.samples[index]\n", "        return x, y\n", "    \n", "dataset150=DataSet(samples=indataset150,labels=np.ones(indataset150.shape[0])*150)\n", "dataset=DataSet(samples=indataset,labels=np.ones(indataset.shape[0])*150)"]}, {"cell_type": "markdown", "id": "3b2e3d77", "metadata": {"tags": ["lect_02", "learner"]}, "source": ["Now that we have constructed a simple dataset, we can go ahead and make a variational autoencoder to describe all this information. Since we are not taking images for the moment, we can do this with just standard MLP layers (i.e., fully connected layers or dense layers or linear layers). Lets go ahead and make an VAE that takes in the 4 inputs (width, length, energy in the front(first 3cm) and energy in the back (last 1cm)) and tries to reproduce these inputs. \n", "\n", "Here is the VAE code below, it's a similar clone to the previous: "]}, {"cell_type": "code", "execution_count": null, "id": "916d461f", "metadata": {"tags": ["lect_02", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L21.2-runcell05\n", "\n", "class VariationalAutoEncoder(nn.Module):\n", "    def __init__(self, input_dims,latent_dims):  \n", "        super(VariationalAutoEncoder, self).__init__()\n", "        self.linear1 = nn.Linear(input_dims, 10*input_dims)\n", "        self.batch = nn.BatchNorm1d(10*input_dims)\n", "        self.linear2 = nn.Linear(10*input_dims, 10*input_dims)\n", "        self.linear3 = nn.Linear(10*input_dims, latent_dims)\n", "        self.linear4 = nn.Linear(10*input_dims, latent_dims)\n", "\n", "        #Now we need sample in phase space \n", "        self.N       = torch.distributions.Normal(0, 1)\n", "        self.N.loc   = self.N.loc \n", "        self.N.scale = self.N.scale\n", "        self.kl = 0\n", "        \n", "        self.decoder_lin = nn.Sequential(\n", "            nn.Linear(latent_dims, 25*input_dims),\n", "            nn.ReLU(True),\n", "            nn.Linear(25*input_dims, 25*input_dims),\n", "            nn.ReLU(True),\n", "            nn.Linear(25*input_dims, input_dims),\n", "        )\n", "\n", "    def encoder(self, x):\n", "        x = F.relu(self.linear1(x))\n", "        x = F.relu(self.batch(self.linear2(x)))\n", "        x = torch.flatten(x, start_dim=1)\n", "        mu =  self.linear3(x) #Mean in the gaussian space\n", "        sigma = torch.exp(self.linear4(x)) #sigma in the space\n", "        z = mu + sigma*self.N.sample(mu.shape) #smear \n", "        self.kl = (sigma**2 + mu**2 - torch.log(sigma) - 1/2).sum() #Now compute the KL divergence\n", "        return z\n", "            \n", "    def encoder_nosmear(self, x):\n", "        x = F.relu(self.linear1(x))\n", "        x = F.relu(self.batch(self.linear2(x)))\n", "        x = torch.flatten(x, start_dim=1)\n", "        mu =  self.linear3(x) #Mean in the gaussian space\n", "        sigma = torch.exp(self.linear4(x)) #sigma in the space\n", "        return mu,sigma\n", "    \n", "    def decoder(self, x):\n", "        x = self.decoder_lin(x)\n", "        return x\n", "    \n", "    def forward(self, x):\n", "        z = self.encoder(x)\n", "        return self.decoder(z)\n", "    \n", "torch.manual_seed(0)\n", "d = 2\n", "vae = VariationalAutoEncoder(input_dims=dataset.nfeatures(),latent_dims=d)\n", "lr = 1e-3 \n", "optim = torch.optim.Adam(vae.parameters(), lr=lr, weight_decay=1e-5)\n", "train_loader = torch.utils.data.DataLoader(dataset150, batch_size=500)\n", "#valid_loader = torch.utils.data.DataLoader(dataset150, batch_size=500)\n", "#test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size,shuffle=True)\n"]}, {"cell_type": "markdown", "id": "2ba1a25f", "metadata": {"tags": ["lect_02", "learner"]}, "source": ["Now, we put in some training and testing code, like we did before. "]}, {"cell_type": "code", "execution_count": null, "id": "3ccb84ac", "metadata": {"tags": ["lect_02", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L21.2-runcell06\n", "\n", "#redefine functions from the previous section (if you have not run L21.1)\n", "\n", "### Training function\n", "def train_epoch(vae, dataloader, optimizer):\n", "    # Set train mode for both the encoder and the decoder\n", "    vae.train()\n", "    train_loss = 0.0\n", "    # Iterate the dataloader (we do not need the label values, this is unsupervised learning)\n", "    for x, _ in dataloader:\n", "        # Move tensor to the proper device\n", "        x_hat = vae(x)\n", "        # Evaluate loss\n", "        loss = ((x - x_hat)**2).sum() + vae.kl\n", "        # Backward pass\n", "        optimizer.zero_grad()\n", "        loss.backward()\n", "        optimizer.step()\n", "        # Print batch loss\n", "        #print('\\t partial train loss (single batch): %f' % (loss.item()))\n", "        train_loss+=loss.item()\n", "\n", "    return train_loss / len(dataloader.dataset)\n", "\n", "### Testing function\n", "def test_epoch(vae, dataloader):\n", "    # Set evaluation mode for encoder and decoder\n", "    vae.eval()\n", "    val_loss = 0.0\n", "    with torch.no_grad(): # No need to track the gradients\n", "        for x, _ in dataloader:\n", "            # Encode data\n", "            encoded_data = vae.encoder(x)\n", "            # Decode data\n", "            x_hat = vae(x)\n", "            loss = ((x - x_hat)**2).sum() + vae.kl\n", "            val_loss += loss.item()\n", "\n", "    return val_loss / len(dataloader.dataset)"]}, {"cell_type": "markdown", "id": "981ecfc0", "metadata": {"tags": ["lect_02", "learner"]}, "source": ["Finally, we will train this with 5k epochs. "]}, {"cell_type": "code", "execution_count": null, "id": "e6db8bc8", "metadata": {"tags": ["lect_02", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L21.2-runcell07\n", "\n", "num_epochs = 5001\n", "\n", "for epoch in range(num_epochs):\n", "    train_loss = train_epoch(vae,train_loader,optim)\n", "    #val_loss = test_epoch(vae,valid_loader)\n", "    if epoch % 500 == 0:\n", "        print('EPOCH {}/{} \\t train loss {:.3f} \\t'.format(epoch + 1, num_epochs,train_loss))\n"]}, {"cell_type": "markdown", "id": "1aa75740", "metadata": {"tags": ["lect_02", "learner"]}, "source": ["Ok, once we have created the VAE. We can test out the performance of the VAE by generating our own events off the latent space and decoding them. In order to generate the events, we are going to assume that VAE did things correctly and embedded all the variations into normal distribution with mean 0 and width 1. In reality, our encoder will give us more details about this, but we want to freely generate events, so lets just try this out. "]}, {"cell_type": "code", "execution_count": null, "id": "7439bd9d", "metadata": {"tags": ["lect_02", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L21.2-runcell08\n", "\n", "def plotVAEOutputs(iLatentDim,iDataSet):\n", "    #generate events assuming a random normal with latent dimension given the the latent space\n", "    testlatent=torch.randn(iDataSet.shape[0],iLatentDim)\n", "    testlatent=testlatent.reshape(iDataSet.shape[0],iLatentDim)\n", "    #now decode thme into observables\n", "    outputvars=vae.decoder(testlatent)\n", "\n", "    xrange=np.arange(0,60,2)\n", "    plt.title('Deposition Length: 150 MeV')\n", "    plt.xlabel('Distance [cm]')\n", "    plt.ylabel('N')\n", "    plt.hist(iDataSet[:,0],label='input',alpha=0.5,bins=xrange)\n", "    plt.hist(outputvars[:,0].detach().numpy(),label='output',alpha=0.5,bins=xrange)\n", "    plt.legend()\n", "    plt.show()\n", "\n", "    xrange=np.arange(-10,10,0.5)\n", "    plt.title('Width: 150 MeV')\n", "    plt.xlabel('Width [cm]')\n", "    plt.ylabel('N')\n", "    plt.hist(iDataSet[:,1],label='input',alpha=0.5,bins=xrange)\n", "    plt.hist(outputvars[:,1].detach().numpy(),label='output',alpha=0.5,bins=xrange)\n", "    plt.legend()\n", "    plt.show()\n", "\n", "    xrange=np.arange(0,10,0.05)\n", "    plt.title('E-Deposit Front: 150 MeV')\n", "    plt.xlabel('E-Deposit Front')\n", "    plt.ylabel('N)')\n", "    plt.hist(iDataSet[:,2],label='input',alpha=0.5,bins=xrange)\n", "    plt.hist(outputvars[:,2].detach().numpy(),label='output',alpha=0.5,bins=xrange)\n", "    plt.legend()\n", "    plt.show()\n", "\n", "    xrange=np.arange(0,60,2)\n", "    plt.title('E-Deposit Back: 150 MeV')\n", "    plt.xlabel('E-Deposit Back')\n", "    plt.ylabel('N)')\n", "    plt.hist(iDataSet[:,3],label='input',alpha=0.5,bins=xrange)\n", "    plt.hist(outputvars[:,3].detach().numpy(),label='output',alpha=0.5,bins=xrange)\n", "    plt.legend()\n", "    plt.show()\n", "\n", "plotVAEOutputs(d,indataset150)"]}, {"cell_type": "markdown", "id": "249fd92f", "metadata": {"tags": ["lect_02", "learner"]}, "source": ["Surprisingly, we have managed to capture many of the features that we expect already. In reality, to really test the generation, we would need to use the input distribution of the latent space, since at no point have we said that a normal distribution with means (0,0) with widths (1,1) captures all of our features. We will show how to get a more accurate comparison in an problem below. Anyway, despite that, we have remarkably captured many of the features. "]}, {"cell_type": "markdown", "id": "023f7c2c", "metadata": {"tags": ["md", "learner", "learner_chopped"]}, "source": ["<a name='exercises_22_2'></a>     \n", "\n", "| [Top](#section_22_0) | [Restart Section](#section_22_2) | [Next Section](#section_22_3) |\n"]}, {"cell_type": "markdown", "id": "b1db6962", "metadata": {"tags": ["md", "learner", "learner_chopped"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Exercise 21.2.1</span>\n", "\n", "Let's test the fidelity of the network. Plot the encoding of our setup using the `corner` plot function, which we will use many times in future lessons. A corner plot shows the posterior distributions of fit parameters, with 2D plots revealing any correlations between parameters. Thus, with a corner plot, we will learn the best estimates for the parameters of the latent space: $\\mu_{1}$, $\\mu_{2}$, $\\sigma_{1}$,  and $\\sigma_{2}$.\n", "\n", "Run the code below, where use the `encoder_nosmear` function to output $\\mu$ and $\\sigma$ of the VAE latent space for each event. Are these values consistent with our expectation, that $\\mu_{1}$, $\\mu_{2}$ are 0 and $\\sigma_{1}$,  and $\\sigma_{2}$ are 1? \n", "\n", "Report the values as a list of numbers `[mu1, mu2, sigma1, sigma2]` with precision `1e-2`. Since it may be the case that your code defines `mu1` and `mu2` oppositely from us (the order is arbitraty), let's explicitly define the `mu` values with `mu1` as the smallest and `mu2` as the largest. So, if you found the following set of parameters: `mu1=0.5`, `mu2=0.1`, `sigma1=0.01`, `sigma2=0.02`, then you should submit this as: `[0.1, 0.5, 0.02, 0.01]`.\n", "\n", "<br>"]}, {"cell_type": "code", "execution_count": null, "id": "5caf1ace", "metadata": {"tags": ["py", "draft", "learner_chopped"]}, "outputs": [], "source": ["#>>>EXERCISE: L21.2.1\n", "\n", "mu,sigma=vae.encoder_nosmear(indataset150)\n", "allvars=np.hstack((mu.detach().numpy(),sigma.detach().numpy()))\n", "corner.corner(allvars,show_titles=True,labels=['$\\mu_{1}$','$\\mu_{2}$','$\\sigma_{1}$','$\\sigma_{2}$'],plot_datapoints=True,quantiles=[0.16, 0.5, 0.84])\n", "plt.show()\n"]}, {"cell_type": "markdown", "id": "6c092ce3", "metadata": {"tags": ["md", "learner", "learner_chopped"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Exercise 21.2.2</span>\n", "\n", "Now we will modify the `plotVAEOutputs` function from `L21.2-runcell08` above, by giving it the values for the latent space, `mu` and `sigma`, that were found by the encoder.  We can then have it sample a normal distribution with these parameters, generate outputs, and compare to the inputs (i.e., true distributions). Run the code below and determine which one of the following characteristics has the most improved agreement between the inputs and outputs of the VAE. \n", "\n", "A) Deposition Length\\\n", "B) Width\\\n", "C) E-Deposit Front\\\n", "D) E-Deposit Back\n", "\n", "<br>"]}, {"cell_type": "code", "execution_count": null, "id": "4a163b88", "metadata": {"tags": ["py", "draft", "learner_chopped"]}, "outputs": [], "source": ["#>>>EXERCISE: L21.2.2\n", "\n", "def plotVAEOutputs_Real(iMu,iSigma,iLatentDim,iDataSet):\n", "    #generate events assuming a random normal, based on the latent space values iMu and iSigma\n", "    testlatent=torch.randn(iMu.shape)\n", "    testlatent=testlatent*iSigma+iMu\n", "    #now decode thme into observables\n", "    outputvars = vae.decoder(testlatent)\n", "    #now because we can, lets ust generate 5 times as many events\n", "    for i in range(0,5):\n", "        testlatent=torch.randn(iMu.shape)\n", "        testlatent=testlatent*iSigma+iMu\n", "        outputvars=torch.cat((outputvars,vae.decoder(testlatent)))\n", "\n", "    xrange=np.arange(0,60,2)\n", "    plt.title('Deposition Length: 150 MeV')\n", "    plt.xlabel('Distance [cm]')\n", "    plt.ylabel('N')\n", "    plt.hist(iDataSet[:,0],label='input',alpha=0.5,bins=xrange,density=True)\n", "    plt.hist(outputvars[:,0].detach().numpy(),label='output',alpha=0.5,bins=xrange,density=True)\n", "    plt.legend()\n", "    plt.show()\n", "\n", "    xrange=np.arange(-10,10,0.5)\n", "    plt.title('Width: 150 MeV')\n", "    plt.xlabel('Width [cm]')\n", "    plt.ylabel('N')\n", "    plt.hist(iDataSet[:,1],label='input',alpha=0.5,bins=xrange,density=True)\n", "    plt.hist(outputvars[:,1].detach().numpy(),label='output',alpha=0.5,bins=xrange,density=True)\n", "    plt.legend()\n", "    plt.show()\n", "\n", "    xrange=np.arange(0,10,0.05)\n", "    plt.title('E-Deposit Front: 150 MeV')\n", "    plt.xlabel('E-Deposit Front')\n", "    plt.ylabel('N)')\n", "    plt.hist(iDataSet[:,2],label='input',alpha=0.5,bins=xrange,density=True)\n", "    plt.hist(outputvars[:,2].detach().numpy(),label='output',alpha=0.5,bins=xrange,density=True)\n", "    plt.legend()\n", "    plt.show()\n", "\n", "    xrange=np.arange(0,60,2)\n", "    plt.title('E-Deposit Back: 150 MeV')\n", "    plt.xlabel('E-Deposit Back')\n", "    plt.ylabel('N)')\n", "    plt.hist(iDataSet[:,3],label='input',alpha=0.5,bins=xrange,density=True)\n", "    plt.hist(outputvars[:,3].detach().numpy(),label='output',alpha=0.5,bins=xrange,density=True)\n", "    plt.legend()\n", "    plt.show()\n", "\n", "mu,sigma=vae.encoder_nosmear(indataset150)\n", "plotVAEOutputs_Real(mu,sigma,d,indataset150)"]}, {"cell_type": "markdown", "id": "c199f252", "metadata": {"tags": ["md", "learner", "learner_chopped"]}, "source": ["<a name='section_22_3'></a>\n", "<hr style=\"height: 1px;\">\n", "\n", "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\">L21.3 Generating Full Bragg Scattering Details </h2>  \n", "\n", "| [Top](#section_22_0) | [Previous Section](#section_22_2) | [Exercises](#exercises_22_3) | [Next Section](#section_22_4) |"]}, {"cell_type": "markdown", "id": "8b742f55", "metadata": {"tags": ["learner"]}, "source": ["*The material in this section is discussed in the video **<a href=\"https://courses.mitxonline.mit.edu/learn/course/course-v1:MITxT+8.S50.3x+3T2023/block-v1:MITxT+8.S50.3x+3T2023+type@sequential+block@seq_LS21/block-v1:MITxT+8.S50.3x+3T2023+type@vertical+block@vert_LS21_vid3\" target=\"_blank\">HERE</a>.** You are encouraged to watch that video and use this notebook concurrently.*"]}, {"cell_type": "markdown", "id": "d5a9538e", "metadata": {"tags": ["lect_03", "learner"]}, "source": ["<h3>Overview</h3>\n", "\n", "Given the success of what was done above, let's look at our events and see if we can try to generate a fully detailed event. Recall that we actually save the energy loss, as well as $x$ and $y$ positions of each proton event. We can translate this information directly into an image by considering the Z-axis as the energy deposited. Let's go ahead and do that, and see what it looks like."]}, {"cell_type": "code", "execution_count": null, "id": "fec0b41f", "metadata": {"scrolled": false, "tags": ["lect_03", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L21.3-runcell01\n", "\n", "def plotImage(iId,ixstep,iestep,iystep):\n", "    #plt.plot(ixstep[iId],iystep[iId])#,iestep[iId])\n", "    #plt.show()\n", "    #Now let's make a regular image \n", "    xbin = np.arange(-1,55, 2)\n", "    ybin = np.arange(-3.75, 3.75, 0.25)\n", "    #xbin = np.arange(-0.5,60.5, 1)\n", "    #ybin = np.arange(-5.125, 5.125, 0.25)\n", "    H, xedges, yedges = np.histogram2d(ixstep.flatten(), iystep.flatten(), bins=(xbin, ybin),weights=iestep.flatten())  \n", "    plt.imshow(H.T,extent=[xedges[0], xedges[-1], yedges[0], yedges[-1]])  \n", "    plt.show()\n", "    #X, Y = np.meshgrid(xedges, yedges)\n", "    #plt.pcolormesh(X,Y,H.T)  \n", "    #plt.show()\n", "\n", "plotImage(-1,xstep150,estep150,ystep150)\n", "plotImage(-1,xstep200,estep200,ystep200)\n", "plotImage(-1,xstep250,estep250,ystep250)\n", "plotImage(-1,xstep300,estep300,ystep300)\n", "\n", "\n", "def makeImageDataSet(iE,ixstep,iestep,iystep):\n", "    dataset=np.empty((0,1,28,28))\n", "    for pX,pE,pY in zip(ixstep,iestep,iystep):\n", "        xbin = np.arange(-1,57, 2)\n", "        ybin = np.arange(-3.625, 3.625, 0.25)\n", "        H, xedges, yedges = np.histogram2d(pX.flatten(), pY.flatten(), bins=(xbin, ybin),weights=pE.flatten())  \n", "        #H, xedges, yedges = np.histogram2d(ixstep.flatten(), iystep.flatten(), bins=(xbin, ybin),weights=iestep.flatten())  \n", "        #plt.imshow(H.T,extent=[xedges[0], xedges[-1], yedges[0], yedges[-1]])  \n", "        #plt.show()\n", "        H = np.reshape(H.T,(1,1,28,28))\n", "        dataset = np.vstack((dataset,H))\n", "    #print(dataset.shape)\n", "    Tdataset = torch.tensor(dataset).float()\n", "    datasetout=DataSet(samples=Tdataset,labels=np.ones(dataset.shape[0])*iE)\n", "    return datasetout,dataset\n", "\n", "image150,dimage150=makeImageDataSet(1.50,xstep150,estep150,ystep150)\n", "image200,dimage200=makeImageDataSet(2.00,xstep200,estep200,ystep200)\n", "image250,dimage250=makeImageDataSet(2.50,xstep250,estep250,ystep250)\n", "image300,dimage300=makeImageDataSet(3.00,xstep300,estep300,ystep300)"]}, {"cell_type": "markdown", "id": "d4de9fda", "metadata": {"tags": ["lect_03", "learner"]}, "source": ["Now, from this let's make a VAE that describes our dataset. We can exploit the VAE architecture used above, just slightly tweaked. Note that the training performed by 'L21.3-runcell04' takes some time to run. At the end of the training, code cell 'L21.3-runcell05' compares the input and regenerated output distributions.\n", "\n", "Given the above images, we are going to use exactly the same architecture that we used in section 1. The next few blocks are repeating everything we did in section 1, but now for our simulated proton energy deposits. \n"]}, {"cell_type": "code", "execution_count": null, "id": "12f3671f", "metadata": {"tags": ["lect_03", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L21.3-runcell02\n", "\n", "class VariationalAutoEncoder(nn.Module):\n", "    def __init__(self, latent_dims):  \n", "        super(VariationalAutoEncoder, self).__init__()\n", "        self.conv1 = nn.Conv2d(1, 8, 3, stride=2, padding=1)\n", "        self.conv2 = nn.Conv2d(8, 16, 3, stride=2, padding=1)\n", "        self.batch2 = nn.BatchNorm2d(16)\n", "        self.conv3 = nn.Conv2d(16, 32, 3, stride=2, padding=0)  \n", "        self.linear1 = nn.Linear(3*3*32, 128)\n", "        self.linear2 = nn.Linear(128, latent_dims)\n", "        self.linear3 = nn.Linear(128, latent_dims)\n", "\n", "        #Now we need sample in phase space \n", "        self.N       = torch.distributions.Normal(0, 1)\n", "        self.N.loc   = self.N.loc \n", "        self.N.scale = self.N.scale\n", "        self.kl = 0\n", "        \n", "        self.unflatten = nn.Unflatten(dim=1, unflattened_size=(32, 3, 3))\n", "\n", "        self.decoder_conv = nn.Sequential(\n", "            nn.ConvTranspose2d(32, 16, 3, stride=2, output_padding=0),\n", "            nn.BatchNorm2d(16),\n", "            nn.ReLU(True),\n", "            nn.ConvTranspose2d(16, 8, 3, stride=2, padding=1, output_padding=1),\n", "            nn.BatchNorm2d(8),\n", "            nn.ReLU(True),\n", "            nn.ConvTranspose2d(8, 1, 3, stride=2, padding=1, output_padding=1)\n", "        )\n", "\n", "        self.decoder_lin = nn.Sequential(\n", "            nn.Linear(latent_dims, 128),\n", "            nn.ReLU(True),\n", "            nn.Linear(128, 3 * 3 * 32),\n", "            nn.ReLU(True)\n", "        )\n", "\n", "\n", "    def encoder(self, x):\n", "        x = F.relu(self.conv1(x))\n", "        x = F.relu(self.batch2(self.conv2(x)))\n", "        x = F.relu(self.conv3(x))\n", "        x = torch.flatten(x, start_dim=1)\n", "        x = F.relu(self.linear1(x))\n", "        mu =  self.linear2(x) #Mean in the gaussian space\n", "        sigma = torch.exp(self.linear3(x)) #sigma in the space\n", "        z = mu + sigma*self.N.sample(mu.shape) #smear \n", "        self.kl = (sigma**2 + mu**2 - torch.log(sigma) - 1/2).sum() #Now compute the KL divergence\n", "        return z\n", "\n", "    def encoder_nosmear(self, x):\n", "        x = F.relu(self.conv1(x))\n", "        x = F.relu(self.batch2(self.conv2(x)))\n", "        x = F.relu(self.conv3(x))\n", "        x = torch.flatten(x, start_dim=1)\n", "        x = F.relu(self.linear1(x))\n", "        mu =  self.linear2(x) #Mean in the gaussian space\n", "        sigma = torch.exp(self.linear3(x)) #sigma in the space\n", "        return mu,sigma\n", "    \n", "    def decoder(self, x):\n", "        x = self.decoder_lin(x)\n", "        x = self.unflatten(x)\n", "        x = self.decoder_conv(x)\n", "        return x\n", "\n", "        \n", "    def forward(self, x):\n", "        z = self.encoder(x)\n", "        return self.decoder(z)\n", "    \n", "torch.manual_seed(0)\n", "d = 4\n", "vae = VariationalAutoEncoder(latent_dims=d)\n", "lr = 1e-2 \n", "optim = torch.optim.Adam(vae.parameters(), lr=lr, weight_decay=1e-5)\n", "train_loader = torch.utils.data.DataLoader(image150, batch_size=500)"]}, {"cell_type": "markdown", "id": "baf261df", "metadata": {"tags": ["lect_03", "learner"]}, "source": ["Finally the training, which we will update in real-time. Looka at how well we match the tracks. Note the first box is to just plot the outputs in real time. \n"]}, {"cell_type": "code", "execution_count": null, "id": "43d539af", "metadata": {"tags": ["lect_03", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L21.3-runcell03\n", "\n", "def plot_ae_outputs(idataset,ivae,n=10):\n", "    plt.figure(figsize=(16,4.5))\n", "    t_idx = np.random.randint(10,size=10)\n", "    for i in range(n):\n", "      ax = plt.subplot(2,n,i+1)\n", "      img = idataset[t_idx[i]][0].unsqueeze(0)\n", "      vae.eval()\n", "      #encoder.eval()\n", "      #decoder.eval()\n", "      with torch.no_grad():\n", "         rec_img  = vae.decoder(vae.encoder(img))\n", "      plt.imshow(img.cpu().squeeze().numpy())#, cmap='gist_gray')\n", "      ax.get_xaxis().set_visible(False)\n", "      ax.get_yaxis().set_visible(False)  \n", "      if i == n//2:\n", "        ax.set_title('Original images')\n", "      ax = plt.subplot(2, n, i + 1 + n)\n", "      plt.imshow(rec_img.cpu().squeeze().numpy())#, cmap='gist_gray')  \n", "      ax.get_xaxis().set_visible(False)\n", "      ax.get_yaxis().set_visible(False)  \n", "      if i == n//2:\n", "         ax.set_title('Reconstructed images')\n", "    plt.show()  \n", "    "]}, {"cell_type": "code", "execution_count": null, "id": "7763453a", "metadata": {"scrolled": true, "tags": ["lect_03", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L21.3-runcell04\n", "\n", "#Note: this will take some time\n", "\n", "num_epochs = 2500\n", "\n", "for epoch in range(num_epochs):\n", "    train_loss = train_epoch(vae,train_loader,optim)\n", "    val_loss=0\n", "    if epoch % 500 == 0:\n", "        print('\\n EPOCH {}/{} \\t train loss {:.3f} \\t val loss {:.3f}'.format(epoch + 1, num_epochs,train_loss,val_loss))\n", "        plot_ae_outputs(image150,vae,n=10)\n", "        \n", "\n", "print(\"final loss\", train_loss)"]}, {"cell_type": "code", "execution_count": null, "id": "b835fcbf", "metadata": {"tags": ["lect_03", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L21.3-runcell05\n", "\n", "def plotVAEImageOutputs(iLatentDim,iDataSet):\n", "    testlatent=torch.randn(iDataSet.shape[0],iLatentDim)\n", "    testlatent=testlatent.reshape(iDataSet.shape[0],iLatentDim)\n", "    rec_img  = vae.decoder(testlatent)\n", "    rec_img  = rec_img.detach().numpy()\n", "\n", "    xbin = np.arange(-0.5,27.5, 1)\n", "    ybin = np.arange(-3.5, 3.5, 0.25)\n", "    plt.plot(xbin,np.mean(np.sum(iDataSet,axis=2),axis=0).flatten(),drawstyle='steps-mid',label='MC')\n", "    plt.plot(xbin,np.mean(np.sum(rec_img,axis=2),axis=0).flatten(),drawstyle='steps-mid',label='NN')\n", "    plt.xlabel('x-distance(cm)')\n", "    plt.show()\n", "    \n", "\n", "    plt.plot(ybin,np.mean(np.sum(iDataSet,axis=3),axis=0).flatten(),drawstyle='steps-mid',label='MC')\n", "    plt.plot(ybin,np.mean(np.sum(rec_img,axis=3),axis=0).flatten(),drawstyle='steps-mid',label='NN')\n", "    plt.xlabel('y-distance(cm)')\n", "    plt.show()\n", "\n", "    xrange=np.arange(0,10,0.5)\n", "    plt.hist(np.sum(iDataSet,axis=2)[0:10].flatten(),label='input',alpha=0.5,bins=xrange,density=True)\n", "    plt.hist(np.sum(rec_img ,axis=2)[0:10].flatten(),label='output',alpha=0.5,bins=xrange,density=True)\n", "    plt.xlabel(\"E-deposit(0-10 pixels)\")\n", "    plt.legend()\n", "    plt.show()\n", "\n", "    xrange=np.arange(0,60,2)\n", "    plt.hist(np.sum(iDataSet,axis=2)[10:20].flatten(),label='input',alpha=0.5,bins=xrange,density=True)\n", "    plt.hist(np.sum(rec_img ,axis=2)[10:20].flatten(),label='output',alpha=0.5,bins=xrange,density=True)\n", "    plt.legend()\n", "    plt.xlabel(\"E-deposit(10-20 pixels)\")\n", "    plt.show()\n", "    \n", "    dimage150_avg = np.mean(iDataSet,axis=0)\n", "    plt.imshow(dimage150_avg[0])\n", "    plt.show()\n", "\n", "    rec_img_avg = np.mean(rec_img,axis=0)\n", "    plt.imshow(rec_img_avg[0])\n", "    plt.show()\n", "\n", "#dimage150_avg = np.mean(dimage150,axis=0)\n", "#plt.imshow(dimage150_avg[0])\n", "#plt.show()\n", "#dimage150_tmp = np.mean(dimage150,axis=0)\n", "#plt.imshow(dimage150[0][0])\n", "#plt.show()\n", "#test=np.mean(np.sum(dimage150,axis=3),axis=0)\n", "plotVAEImageOutputs(d,dimage150)\n", "torch.save(vae.state_dict(), 'data/L22/vae_150.pt')"]}, {"cell_type": "markdown", "id": "4f86b9d5", "metadata": {"tags": ["md", "learner", "learner_chopped"]}, "source": ["Now, we can see that we get bettet agreement for our VAE in terms of modelling the effects, when compared to just trying to model the high-level observables. However, we need to a little careful. In the previous, we were modelling high levle obserrables tha tare precise. Here we are trying to capture a quantized(pixelated) image, which we do. Really, we have taken a problem with complex inputs and outputs and replaced the training to take simple images and produced output images. While there are more inputs and outputs, the actual obserables are quite simple. We are just taking in images of particle showers, simplifying them, and reproducing hte same particle showers. The shower is a continuous object with a characteristic shape. This is much more physically meaningful than high level observable. We can explore this more in the problems below. \n"]}, {"cell_type": "markdown", "id": "3a9d93d2", "metadata": {"tags": ["md", "learner", "learner_chopped"]}, "source": ["<a name='exercises_22_3'></a>     \n", "\n", "| [Top](#section_22_0) | [Restart Section](#section_22_3) | [Next Section](#section_22_4) |\n"]}, {"cell_type": "markdown", "id": "104570ae", "metadata": {"tags": ["md", "learner", "learner_chopped"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Exercise 21.3.1</span>\n", "\n", "As we did in the last section, let's look at the latent space. Run the code below, where we again use the `encoder_nosmear` function to output $\\mu$ and $\\sigma$ of the VAE latent space for each event, and then make a corner plot. Does it look more regular than before?\n", "\n", "What are the mus and sigmas for all 4 dimensions? Report the values as a list of numbers `[mu1,mu2,mu3,mu4,sigma1,sigma2,sigma3,sigma4]` with precision `1e-2`. Again, since it may be the case that your code defines the `mu` values oppositely from us (the order is arbitraty), let's explicitly define the `mu` values with `mu1` as the smallest, in ascending order. Note some `mu` values could be negative, so they should occur first in your list!\n", "\n", "<br>"]}, {"cell_type": "code", "execution_count": null, "id": "28f8913e", "metadata": {"tags": ["py", "draft", "learner_chopped"]}, "outputs": [], "source": ["#>>>EXERCISE: L21.3.1\n", "\n", "mu,sigma=vae.encoder_nosmear(torch.tensor(dimage150).float())\n", "allvars=np.hstack((mu.detach().numpy(),sigma.detach().numpy()))\n", "corner.corner(allvars,show_titles=True,labels=['$\\mu_{1}$','$\\mu_{2}$','$\\mu_{3}$','$\\mu_{4}$','$\\sigma_{1}$','$\\sigma_{2}$','$\\sigma_{3}$','$\\sigma_{4}$'],plot_datapoints=True,quantiles=[0.16, 0.5, 0.84])\n"]}, {"cell_type": "markdown", "id": "558bc58a", "metadata": {"tags": ["md", "learner", "learner_chopped"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Exercise 22.3.2</span>\n", "\n", "Again, lets generate events off the latent space found from our encoder. Run the code below, where we have given it the $\\mu$ and $\\sigma$ values found above, and compare the inputs and outputs of the VAE for various characteristics.\n", "\n", "Does the agreement between inputs and outputs improve, compared to the results of cell `L21.3-runcell05`?\n", "\n", "A) Yes\\\n", "B) No\\\n", "C) Maybe?\n"]}, {"cell_type": "code", "execution_count": null, "id": "409d855a", "metadata": {"tags": ["py", "draft", "learner_chopped"]}, "outputs": [], "source": ["#>>>EXERCISE: L21.3.2\n", "\n", "def plotVAEImageOutputs_real(iMu,iSigma,iLatentDim,iDataSet):    \n", "    testlatent=torch.randn(iMu.shape)\n", "    testlatent=testlatent*iSigma+iMu\n", "    rec_img  = vae.decoder(testlatent)\n", "    rec_img  = rec_img.detach().numpy()\n", "\n", "    xbin = np.arange(-0.5,27.5, 1)\n", "    ybin = np.arange(-3.5, 3.5, 0.25)\n", "    plt.plot(xbin,np.mean(np.sum(iDataSet,axis=2),axis=0).flatten(),drawstyle='steps-mid',label='MC')\n", "    plt.plot(xbin,np.mean(np.sum(rec_img,axis=2),axis=0).flatten(),drawstyle='steps-mid',label='NN')\n", "    plt.xlabel('x-distance(cm)')\n", "    plt.show()\n", "\n", "\n", "    plt.plot(ybin,np.mean(np.sum(iDataSet,axis=3),axis=0).flatten(),drawstyle='steps-mid',label='MC')\n", "    plt.plot(ybin,np.mean(np.sum(rec_img,axis=3),axis=0).flatten(),drawstyle='steps-mid',label='NN')\n", "    plt.xlabel('y-distance(cm)')\n", "    plt.show()\n", "\n", "    xrange=np.arange(0,10,0.5)\n", "    plt.hist(np.sum(iDataSet,axis=2)[0:10].flatten(),label='input',alpha=0.5,bins=xrange,density=True)\n", "    plt.hist(np.sum(rec_img ,axis=2)[0:10].flatten(),label='output',alpha=0.5,bins=xrange,density=True)\n", "    plt.xlabel(\"E-deposit(0-10 pixels)\")\n", "    plt.legend()\n", "    plt.show()\n", "\n", "    xrange=np.arange(0,60,2)\n", "    plt.hist(np.sum(iDataSet,axis=2)[10:20].flatten(),label='input',alpha=0.5,bins=xrange,density=True)\n", "    plt.hist(np.sum(rec_img ,axis=2)[10:20].flatten(),label='output',alpha=0.5,bins=xrange,density=True)\n", "    plt.legend()\n", "    plt.xlabel(\"E-deposit(10-20 pixels)\")\n", "    plt.show()\n", "\n", "    dimage150_avg = np.mean(iDataSet,axis=0)\n", "    plt.imshow(dimage150_avg[0])\n", "    plt.show()\n", "\n", "    rec_img_avg = np.mean(rec_img,axis=0)\n", "    plt.imshow(rec_img_avg[0])\n", "    plt.show()\n", "    \n", "mu,sigma=vae.encoder_nosmear(torch.tensor(dimage150).float())\n", "plotVAEImageOutputs_real(mu,sigma,d,dimage150)"]}, {"cell_type": "markdown", "id": "5af1f000", "metadata": {"tags": ["md", "learner", "learner_chopped"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Exercise 21.3.3</span>\n", "\n", "Now, let's generate similar plots at another energy. Try repeating the training procedure in this section using the `dimage300` dataset. What qualitative differences do you observe? Select ALL options that apply:\n", "\n", "\n", "A) The tracks are spread out more spatially.\\\n", "B) The VAE has a higher loss.\\\n", "C) The VAE does a comparable job at matching the histograms compared to the case with the 150 Mev dataset.\n", "\n", "\n", "Ultimately, we do not want to be required to create a new simulation for every energy. Rather, we want to condition the output of the decoder on the energy that is given. We will discuss this in the next section!\n", "\n", "<br>"]}, {"cell_type": "markdown", "id": "5ff41edd", "metadata": {"tags": ["md", "learner", "learner_chopped"]}, "source": ["<a name='section_22_4'></a>\n", "<hr style=\"height: 1px;\">\n", "\n", "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\">L21.4 Conditional VAEs allowing for energy based generation </h2>  \n", "\n", "\n", "\n", "| [Top](#section_22_0) | [Previous Section](#section_22_3) | [Exercises](#exercises_22_4) | [Next Section](#section_22_5) |"]}, {"cell_type": "markdown", "id": "41b30c80", "metadata": {"tags": ["learner"]}, "source": ["*The material in this section is discussed in the video **<a href=\"https://courses.mitxonline.mit.edu/learn/course/course-v1:MITxT+8.S50.3x+3T2023/block-v1:MITxT+8.S50.3x+3T2023+type@sequential+block@seq_LS21/block-v1:MITxT+8.S50.3x+3T2023+type@vertical+block@vert_LS21_vid4\" target=\"_blank\">HERE</a>.** You are encouraged to watch that video and use this notebook concurrently.*"]}, {"cell_type": "markdown", "id": "0ea667c9", "metadata": {"tags": ["lect_04", "learner"]}, "source": ["<h3>Overview</h3>\n", "\n", "Now that we have created a basic VAE that captures most of the features from our Monte Carlo simulation, let's now train for all of our beam energies.\n", "\n", "Training with all of the beam energies is a bit trickier, because we would like to embed our knowledge of the energy into the VAE so that we can decode our setup with the knowledge of the beam energy. We can think of this as\n", "our decoder $d(x)$ now needs to be conditional on the beam energy. We can write this as:\n", "\n", "$$\n", "d\\left(x|E\\right) = f_{NN}\\left(\\mathcal{N}(\\vec{x}|\\vec{\\sigma}),E\\right)\n", "$$\n", "\n", "Where $f_{NN}$ is our neural network, which now takes in the sampled distribution, and the energy. The scheme here is that  we are adding Energy to our latent space as an additional input that we do not sample. This construction is known as a conditional VAE, since now the latent space construction changes, depending on the beam energy. Let's take a look at the architecture.\n"]}, {"cell_type": "code", "execution_count": null, "id": "c3961b18", "metadata": {"tags": ["lect_04", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L21.4-runcell01\n", "\n", "class CondVariationalAutoEncoder(nn.Module):\n", "    def __init__(self, latent_dims):  \n", "        super(CondVariationalAutoEncoder, self).__init__()\n", "        self.conv1 = nn.Conv2d(1, 8, 3, stride=2, padding=1)\n", "        self.conv2 = nn.Conv2d(8, 16, 3, stride=2, padding=1)\n", "        self.batch2 = nn.BatchNorm2d(16)\n", "        self.conv3 = nn.Conv2d(16, 32, 3, stride=2, padding=0)  \n", "        self.linear1  = nn.Linear(3*3*32, 64)\n", "        self.linear1a = nn.Linear(64, 8)\n", "        self.linear1b = nn.Linear(9,  8)\n", "        self.linear2 = nn.Linear(8, latent_dims)\n", "        self.linear3 = nn.Linear(8, latent_dims)\n", "\n", "        #Now we need sample in phase space \n", "        self.N       = torch.distributions.Normal(0, 1)\n", "        self.N.loc   = self.N.loc \n", "        self.N.scale = self.N.scale\n", "        self.kl = 0\n", "        \n", "        self.unflatten = nn.Unflatten(dim=1, unflattened_size=(32, 3, 3))\n", "\n", "        self.decoder_conv = nn.Sequential(\n", "            nn.ConvTranspose2d(32, 16, 3, stride=2, output_padding=0),\n", "            #nn.BatchNorm2d(16),\n", "            nn.ReLU(True),\n", "            nn.ConvTranspose2d(16, 8, 3, stride=2, padding=1, output_padding=1),\n", "            nn.BatchNorm2d(8),\n", "            nn.ReLU(True),\n", "            nn.ConvTranspose2d(8, 1, 3, stride=2, padding=1, output_padding=1)\n", "        )\n", "\n", "        self.decoder_lin = nn.Sequential(\n", "            nn.Linear(latent_dims+1, 64),\n", "            nn.ReLU(True),\n", "            nn.Linear(64, 3 * 3 * 32),\n", "            nn.ReLU(True)\n", "        )\n", "\n", "\n", "    def encoder(self, x, c): #c is our condition\n", "        x = F.relu(self.conv1(x))\n", "        #x = F.relu(self.batch2(self.conv2(x)))\n", "        x = F.relu(self.conv2(x))\n", "        x = F.relu(self.conv3(x))\n", "        x = torch.flatten(x, start_dim=1)\n", "        x = F.relu(self.linear1(x))\n", "        x = F.relu(self.linear1a(x))\n", "        x = torch.hstack((x,c))\n", "        x = F.relu(self.linear1b(x))\n", "        mu =  self.linear2(x) #Mean in the gaussian space with the condition\n", "        sigma = torch.exp(self.linear3(x)) #sigma in the space with the condition\n", "        z = mu + sigma*self.N.sample(mu.shape) #smear \n", "        self.kl = (sigma**2 + mu**2 - torch.log(sigma) - 1/2).sum() #Now compute the KL divergence\n", "        return z\n", "\n", "            \n", "    def decoder(self, x, c):\n", "        x = torch.hstack((x,c))\n", "        x = self.decoder_lin(x)\n", "        x = self.unflatten(x)\n", "        x = self.decoder_conv(x)\n", "        return x\n", "\n", "        \n", "    def forward(self, x, c):\n", "        z = self.encoder(x, c)\n", "        return self.decoder(z, c)\n", "    \n", "torch.manual_seed(0)\n", "d = 6\n", "cvae_proton_image = CondVariationalAutoEncoder(latent_dims=d)\n", "lr = 1e-2 \n", "optim = torch.optim.Adam(cvae_proton_image.parameters(), lr=lr, weight_decay=1e-5)\n", "from torch.utils.data import ConcatDataset\n", "megeimage=ConcatDataset([image150, image200,image250,image300])\n", "train_loader = torch.utils.data.DataLoader(megeimage, batch_size=500)\n", "#from torchsummary import summary\n", "#summary(cvae_proton_image, ((1, 28, 28),1))"]}, {"cell_type": "markdown", "id": "7351254d", "metadata": {"tags": ["lect_04", "learner"]}, "source": ["Note the subtleties here. For this setup, we are feeding the condition, i.e., the index 'c' which denoted the beam energy, in at a few different points. The condition comes in before the latent space is constructed. The condition also comes into the decoder. Note also that the dataset being used is a concatenation of the results for all four beam energies. The point being that we know the condition and so we have the liberty to put this in wherever we want.\n", "\n", "Since, we know the condition at training time and at generation time, we are going to feed it in at all points. What this means is that, when we build the latent space, we will feed the conidtion c into the neural netowrk after we have embedded the images, to help with the correct choice of $\\mu$ and $\\sigma$. Additionally, when we generate events, we will also give $c$ as an input in addition to the randomly sampled point in the latent space. This is equivalent to attaching another dimension $c$ to the latent space, which captures the exact information o this event that we know. Putting in $c$ at a few points does make the network a little harder to generalize. However, we will find that it reproduces our results well. \n", "\n", "\n", "Let's go ahead and train it. We will have to rewrite the training functions that we used previously, so those will be redefined in the code below. Note that we are not bothering with a validation dataset, this is really not the right way to do these things, but in the interest of making this lesson a little faster, we will skip the validation dataset. "]}, {"cell_type": "code", "execution_count": null, "id": "d94e0f5b", "metadata": {"tags": ["lect_04", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L21.4-runcell02\n", "\n", "def plot_ae_outputs(idataset,ivae,n=10):\n", "    plt.figure(figsize=(16,4.5))\n", "    t_idx = np.random.randint(10,size=10)\n", "    for i in range(n):\n", "      ax = plt.subplot(2,n,i+1)\n", "      img = idataset[t_idx[i]][0].unsqueeze(0)\n", "      ivae.eval()\n", "      #encoder.eval()\n", "      #decoder.eval()\n", "      npones=np.ones((1,1))*1.50\n", "      beam=torch.tensor(npones).float()\n", "      with torch.no_grad():\n", "         rec_img  = ivae.decoder(ivae.encoder(img,beam),beam)\n", "      plt.imshow(img.cpu().squeeze().numpy())#, cmap='gist_gray')\n", "      ax.get_xaxis().set_visible(False)\n", "      ax.get_yaxis().set_visible(False)  \n", "      if i == n//2:\n", "        ax.set_title('Original images')\n", "      ax = plt.subplot(2, n, i + 1 + n)\n", "      plt.imshow(rec_img.cpu().squeeze().numpy())#, cmap='gist_gray')  \n", "      ax.get_xaxis().set_visible(False)\n", "      ax.get_yaxis().set_visible(False)  \n", "      if i == n//2:\n", "         ax.set_title('Reconstructed images')\n", "    plt.show()  \n", "\n", "### Training function\n", "def train_epoch(vae, dataloader, optimizer):\n", "    # Set train mode for both the encoder and the decoder\n", "    vae.train()\n", "    train_loss = 0.0\n", "    # Iterate the dataloader (we do not need the label values, this is unsupervised learning)\n", "    for x, c in dataloader: \n", "        # Move tensor to the proper device\n", "        c=c.reshape(len(c),1).float()\n", "        x_hat = vae(x,c)\n", "        # Evaluate loss\n", "        loss = ((x - x_hat)**2).sum() + vae.kl\n", "        # Backward pass\n", "        optimizer.zero_grad()\n", "        loss.backward()\n", "        optimizer.step()\n", "        # Print batch loss\n", "        #print('\\t partial train loss (single batch): %f' % (loss.item()))\n", "        train_loss+=loss.item()\n", "\n", "    return train_loss / len(dataloader.dataset)\n", "\n", "lr = 1e-3\n", "optim = torch.optim.Adam(cvae_proton_image.parameters(), lr=lr, weight_decay=1e-5)\n", "\n", "num_epochs = 500\n", "\n", "for epoch in range(num_epochs):\n", "    train_loss = train_epoch(cvae_proton_image,train_loader,optim)\n", "    val_loss=0\n", "    if epoch % 500 == 0 or epoch == num_epochs-1:\n", "        print('\\n EPOCH {}/{} \\t train loss {:.3f} \\t val loss {:.3f}'.format(epoch + 1, num_epochs,train_loss,val_loss))\n", "        plot_ae_outputs(image150,cvae_proton_image,n=10)"]}, {"cell_type": "markdown", "id": "872037a7", "metadata": {"tags": ["lect_04", "learner"]}, "source": ["Now, let's see how well our conditional VAE models the shower shapes, as we vary the beam energy. For now we will just pick two energies to plot, but feel free to uncomment others if you feel like. "]}, {"cell_type": "code", "execution_count": null, "id": "b86574ca", "metadata": {"scrolled": false, "tags": ["lect_04", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L21.4-runcell03\n", "\n", "def plotCondVAEImageOutputs(iE,iLatentDim,iDataSet,iCVAE):\n", "    testlatent=torch.randn(iDataSet.shape[0],iLatentDim)\n", "    testlatent=testlatent.reshape(iDataSet.shape[0],iLatentDim)\n", "    beamenergy = torch.ones(iDataSet.shape[0],1)*iE\n", "    rec_img  = iCVAE.decoder(testlatent,beamenergy)\n", "    rec_img  = rec_img.detach().numpy()\n", "\n", "    xbin = np.arange(-0.5,27.5, 1)\n", "    ybin = np.arange(-3.5, 3.5, 0.25)\n", "    plt.plot(xbin,np.mean(np.sum(iDataSet,axis=2),axis=0).flatten(),drawstyle='steps-mid',label='MC')\n", "    plt.plot(xbin,np.mean(np.sum(rec_img,axis=2),axis=0).flatten(),drawstyle='steps-mid',label='NN')\n", "    plt.xlabel('x-distance(cm)')\n", "    plt.show()\n", "    \n", "\n", "    plt.plot(ybin,np.mean(np.sum(iDataSet,axis=3),axis=0).flatten(),drawstyle='steps-mid',label='MC')\n", "    plt.plot(ybin,np.mean(np.sum(rec_img,axis=3),axis=0).flatten(),drawstyle='steps-mid',label='NN')\n", "    plt.xlabel('y-distance(cm)')\n", "    plt.show()\n", "\n", "    xrange=np.arange(0,20,1)\n", "    plt.hist(np.sum(iDataSet,axis=2)[0:10].flatten(),label='input',alpha=0.5,bins=xrange,density=True)\n", "    plt.hist(np.sum(rec_img ,axis=2)[0:10].flatten(),label='output',alpha=0.5,bins=xrange,density=True)\n", "    plt.legend()\n", "    plt.show()\n", "\n", "    xrange=np.arange(0,60,2)\n", "    plt.hist(np.sum(iDataSet,axis=2)[12:20].flatten(),label='input',alpha=0.5,bins=xrange,density=True)\n", "    plt.hist(np.sum(rec_img ,axis=2)[12:20].flatten(),label='output',alpha=0.5,bins=xrange,density=True)\n", "    plt.legend()\n", "    plt.show()\n", "    \n", "    dimage150_avg = np.mean(iDataSet,axis=0)\n", "    plt.imshow(dimage150_avg[0])\n", "    plt.show()\n", "\n", "    rec_img_avg = np.mean(rec_img,axis=0)\n", "    plt.imshow(rec_img_avg[0])\n", "    plt.show()\n", "\n", "plotCondVAEImageOutputs(1.50,d,dimage150,cvae_proton_image)\n", "#plotCondVAEImageOutputs(2.00,d,dimage200,cvae_proton_image)\n", "#plotCondVAEImageOutputs(2.25,d,dimage200,cvae_proton_image)\n", "plotCondVAEImageOutputs(2.50,d,dimage250,cvae_proton_image)\n", "#plotCondVAEImageOutputs(3.00,d,dimage300,cvae_proton_image)\n", "#torch.save(cvae_proton_image.state_dict(), 'cvae_test.pt')"]}, {"cell_type": "markdown", "id": "78fa02a8", "metadata": {"tags": ["lect_04", "learner"]}, "source": ["Now what is the point of doing all this work Recall that it took a bit of time to generate samples with our stepping analytic simulation. Lets now sample events with our conditional VAE, and we can see how much faster we are. \n", "\n", "In the code beloy we will generate 250 events with either the conditional VAE or just our stepping simulation. \n"]}, {"cell_type": "code", "execution_count": null, "id": "69563505", "metadata": {"tags": ["lect_04", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L21.4-runcell04\n", "\n", "import time\n", "\n", "def generate(iLatentDim,iN,iCVAE,iE):\n", "    testlatent=torch.randn(iN,iLatentDim)\n", "    testlatent=testlatent.reshape(iN,iLatentDim)\n", "    beamenergy = torch.ones(testlatent.shape[0],1)*iE\n", "    rec_img  = iCVAE.decoder(testlatent,beamenergy)\n", "    rec_img  = rec_img.detach().numpy()\n", "    return rec_img\n", "\n", "N=250\n", "start=time.time()\n", "generate(d,N,cvae_proton_image,1.5)\n", "stop=time.time()\n", "print(\"Time to generate 250 events:\",(stop-start))\n", "timeNN=(stop-start)\n", "\n", "start=time.time()\n", "simNYParallelSample(ie=150,im=mproton,iN=N,idt=1e-10,iZ=8)\n", "stop=time.time()\n", "print(\"Time to generate 250 events:\",(stop-start))\n", "timeGen=(stop-start)\n", "\n", "print(\"===> speed up\",timeGen/timeNN)"]}, {"cell_type": "markdown", "id": "7d9688ef", "metadata": {"tags": ["lect_04", "learner"]}, "source": ["We see a factor of over 500 speed up in our ability to generate events. This is a remarkable speed up and means that if our NN is good enough, we can use it to replace many taxing elements of simulation. This can have a substantial impact on downstream processing. "]}, {"cell_type": "markdown", "id": "37072d39", "metadata": {"tags": ["lect_04", "learner"]}, "source": ["<h3>Creating a more expressive model with Normalizing Flows</h3>\n", "\n", "Now, if we really want to make our model extra expressive, we can consider adding *normalizing flow layers*. A normalizing flow is a type of generative model that learns a series of invertible transformations to map samples from a simple probability distribution (e.g., a standard normal distribution) to a more complex target distribution. In our case, the flow would replace the existing Gaussian sample with a Gaussian sample in a transformed space. The iterative transforming in a normalizing flow can make the latent space progressively more and more expressive. We will explore this in a slightly different concept later on. \n", "\n", "**We will skip this for now, but note here that it could be used to make a more expressive model, that could model higher order correlations, capture large dimneionsal spaces, and model more complicated features within the data. We will see this in our future lectures on likelihood-free inference (L24).**"]}, {"cell_type": "markdown", "id": "11a64cc5", "metadata": {"tags": ["md", "learner", "learner_chopped"]}, "source": ["<a name='exercises_22_4'></a>     \n", "\n", "| [Top](#section_22_0) | [Restart Section](#section_22_4) | [Next Section](#section_22_5) |\n"]}, {"cell_type": "markdown", "id": "eed0163e", "metadata": {"tags": ["md", "learner", "learner_chopped"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Exercise 21.4.1</span>\n", "\n", "Rerun the training done in code cell `L21.4-runcell02` for 2500 epochs instead of only 500 (note that this will take some time!). Then use code cell `L21.4-runcell03` to look at the comparison of input and reconstructed distributions. Do the features of the decoded output improve? What is the approximate value of the training loss that you achieve at the end of this expanded training? Report your answer as a number with precision `1e1`.\n", "\n", "<br>"]}, {"cell_type": "markdown", "id": "2e4f40f0", "metadata": {"tags": ["md", "learner", "learner_chopped"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Exercise 21.4.2</span>\n", "\n", "With this new data (trained for 2500 epochs), use `plotCondVAEImageOutputs` to model the shower shape for a beam of initial energy 225 MeV, which is not one of the values that we used to train, but falls within the range of the training data. Also try 400 MeV, which falls outside the range of the training data. How does these look?\n", "\n", "Which do you think the VAE is more capable of modeling, based on the training? Enter your answer for which energy would be modeled better, as number in units of MeV.\n", "\n", "<br>"]}, {"cell_type": "markdown", "id": "e06eac65", "metadata": {"tags": ["md", "learner", "learner_chopped"]}, "source": ["<a name='section_22_5'></a>\n", "<hr style=\"height: 1px;\">\n", "\n", "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\">L21.5 Bootstrapping </h2>  \n", "\n", "\n", "| [Top](#section_22_0) | [Previous Section](#section_22_4) | [Exercises](#exercises_22_5) | [Next Section](#section_22_6) |"]}, {"cell_type": "markdown", "id": "a4d40b04", "metadata": {"tags": ["learner"]}, "source": ["*The material in this section is discussed in the video **<a href=\"https://courses.mitxonline.mit.edu/learn/course/course-v1:MITxT+8.S50.3x+3T2023/block-v1:MITxT+8.S50.3x+3T2023+type@sequential+block@seq_LS21/block-v1:MITxT+8.S50.3x+3T2023+type@vertical+block@vert_LS21_vid5\" target=\"_blank\">HERE</a>.** You are encouraged to watch that video and use this notebook concurrently.*"]}, {"cell_type": "markdown", "id": "bc64de78", "metadata": {"tags": ["lect_05", "learner"]}, "source": ["<h3>Overview</h3>\n", "\n", "When we look at the above generation, the full image with a full energy profile can yield a shape. We can run this a lot and treat the resulting shape as a simulation. However, when we quote uncertainties on this shape, **we can't treat this as a Poisson uncertainty on each bin, since the bins are correlated.**\n", "\n", "To get the full uncertainty of this setup, we really need to go a bit further and deploy techniques that can account for the fact that the whole shape is correlated. There are really two ways to do this:\n", "\n", "1. Write down all the uncertainties going into how you generate your simulation and vary them.\n", "   * For above, this includes, but is not limited to:\n", "     * uncertainty in the beam profile\n", "     * uncertainty in the energy distribution\n", "     * uncertainty in the detector shape\n", "     * uncertainty in the training\n", "     * ...\n", "   * However, this method presents the following issues:\n", "     * the uncertainty in the training can be very hard to estimate, which may require multiple trainings\n", "     * We can often miss uncertainties, or we just ignore them (e.g. uncertainty due to Landau sampling)\n", "     \n", "     \n", "2. Reverse engineer the uncertainty from the ultimate variations in the data.\n", "   * Sometimes it's just too complicated to get the uncertainty from inputs\n", "   * We can analyze the uncertainty by removing events and looking at the prediction variations (this involves some assumptions about uncertainty)\n", "   * This is called **Bootstrapping**\n"]}, {"cell_type": "markdown", "id": "dd7ecfb1", "metadata": {"tags": ["lect_05", "learner"]}, "source": ["<h3>An Examples</h3>\n", "\n", "Now before we go ahead and try to solve the problems of our simulation, let's do some very basic bootstrap examples. Let's sample 500 events from a uniform distribution spanning 100 to 300.\n"]}, {"cell_type": "code", "execution_count": null, "id": "d686c921", "metadata": {"tags": ["lect_05", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L21.5-runcell01\n", "\n", "np.random.seed(0)\n", "\n", "samples = np.random.uniform(100,300,500)\n", "plt.hist(samples)\n", "plt.show()\n", "\n", "print(\"Mean:\",np.mean(samples))\n", "print(\"RMS:\",np.std(samples))"]}, {"cell_type": "markdown", "id": "a8b1402b", "metadata": {"tags": ["lect_05", "learner"]}, "source": ["Ok, so my first question for you is, what is the analytic mean and standard deviation of this sample?\n", "\n", "\n", "This is a just a flat distribution, so we can immediately write the mean and standard deviation of a <a href=\"https://en.wikipedia.org/wiki/Continuous_uniform_distribution\" target=\"_blank\">flat distribution</a> ranging from $a$ to $b$ as\n", "\n", "$$\n", "\\bar{x} = \\frac{1}{(b-a)}\\\\\n", "\\sigma_{x} = \\frac{b-a}{\\sqrt{12}}\n", "$$\n", "\n", "Secondly, we can ask ourselves what the uncertainty on the mean and standard variance is for $N$ measurements. If you recall early on in this class, these can be computing using the variance in the mean over a sample and variance of the standard deviation over the sample for $N$ samples. Analytically, we can write this as:\n", "\n", "$$\n", "\\sigma_{\\bar{x}} = \\frac{\\sigma_{x}}{\\sqrt{N}} \\\\\n", "\\sigma_{\\sigma_{x}} = \\frac{\\sigma_{x}}{\\sqrt{2N}}\n", "$$\n", "\n", "Now, what if we want to compute the uncertainty in the kurtosis or perhaps the ratio of the kurtosis to the mean distribution, or something else, how would we compute that?\n", "\n", "Well....we can do it analytically, but let's try another approach\n", "\n", "Let's resample our existing distribution with a random Poisson sampler, and make a toy experiment. We can then proceed to make many toys and then look at the distribution of our means and standard deviations, and see if they agree with our analytical forms.\n", "\n", "To do that, we are going to use the random choice, which is our Poisson sampler. Let's take a look:"]}, {"cell_type": "code", "execution_count": null, "id": "9f1a5970", "metadata": {"tags": ["lect_05", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L21.5-runcell02\n", "\n", "arr=np.arange(10)\n", "test=np.random.choice(arr,size=5)\n", "print(test)\n", "test=np.random.choice(arr,size=10)\n", "print(test)\n", "plt.hist(test)\n", "test=np.random.choice(arr,size=20)\n", "print(test)"]}, {"cell_type": "markdown", "id": "cbeda103", "metadata": {"tags": ["lect_05", "learner"]}, "source": ["Note that we expect to have duplicates when using a Poisson sampler. The core idea is that if we select a subset of our dataset by Poisson sampling it, we get a notion for how much our dataset will vary if we just choose differently from our base dataset.\n", "\n", "Let's go ahead and compute the mean and RMS of our data. "]}, {"cell_type": "code", "execution_count": null, "id": "0fe2b8e7", "metadata": {"tags": ["lect_05", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L21.5-runcell03\n", "\n", "sample=np.random.choice(samples, size = 500)\n", "print(\"Mean:\",np.mean(sample))\n", "print(\"RMS:\",np.std(sample))\n", "\n", "boot_means = []\n", "boot_stds  = []\n", "for _ in range(10000):\n", "    boot_sample = np.random.choice(samples,replace = True, size = 500) # take a random sample each iteration\n", "    boot_means.append(np.mean(boot_sample)) # append the mean to boot_means\n", "    boot_stds.append(np.std(boot_sample)) # append the mean to boot_means\n", "boot_means_np = np.array(boot_means) # transform it into a numpy array for calculation\n", "boot_stds_np = np.array(boot_stds)\n", "\n", "plt.hist(boot_means_np)\n", "plt.show()\n", "\n", "print(\"Mean of samples:\",np.mean(boot_means_np))\n", "print(\"Std of mean of samples:\",np.std(boot_means_np))\n", "\n", "plt.hist(boot_stds_np)\n", "plt.show()\n", "\n", "print(\"Mean of samples:\",np.mean(boot_stds_np))\n", "print(\"Std of mean of samples:\",np.std(boot_stds_np))"]}, {"cell_type": "markdown", "id": "eafbef61", "metadata": {"tags": ["lect_05", "learner"]}, "source": ["Now let's compare this with the expected values from analytic calculations and see how well we do."]}, {"cell_type": "code", "execution_count": null, "id": "ab824c13", "metadata": {"tags": ["lect_05", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L21.5-runcell04\n", "\n", "analytic         = (300.+100.)/2.\n", "analytic_std     = (300.-100.)/np.sqrt(12.) \n", "analytic_err     = analytic_std/np.sqrt(500.)\n", "analytic_std_err = analytic_std/np.sqrt(500.)/2.\n", "print(\"Mean of samples:\",np.mean(boot_means_np),\"+/-\",np.std(boot_means_np)\n", "      ,\"\\nAnalytic:\",analytic,\"+/-\",analytic_err)\n", "\n", "print(\"Std of samples:\",np.mean(boot_stds_np),\"+/-\",np.std(boot_stds_np)\n", "      ,\"\\nAnalytic:\",analytic_std,\"+/-\",analytic_std_err)\n"]}, {"cell_type": "markdown", "id": "2b04c4d8", "metadata": {"tags": ["lect_05", "learner"]}, "source": ["Now, interestingly, what if we did the same thing but just randomly sampled every time. This would really be the correct way to get the variance. However, we sometimes don't have the opportunity or the computing power to do this. Let's go ahead and try it with the full computing power for comparison, as a replacement of the analytic."]}, {"cell_type": "code", "execution_count": null, "id": "1fe3defa", "metadata": {"tags": ["lect_05", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L21.5-runcell05\n", "\n", "samp_means = []\n", "samp_stds  = []\n", "for _ in range(10000):\n", "    samp_sample = np.random.uniform(100,300,500)\n", "    samp_means.append(np.mean(samp_sample)) # append the mean to boot_means\n", "    samp_stds.append(np.std(samp_sample)) # append the mean to boot_means\n", "samp_means_np = np.array(samp_means) # transform it into a numpy array for calculation\n", "samp_stds_np = np.array(samp_stds)\n", "\n", "print(\"Mean of samples:\",np.mean(samp_means_np),\"+/-\",np.std(samp_means_np)\n", "      ,\"\\nBoot:\",np.mean(boot_means_np),\"+/-\",np.std(boot_means_np))\n", "\n", "print(\"Std of samples:\",np.mean(samp_stds_np),\"+/-\",np.std(samp_stds_np)\n", "      ,\"\\nBoot:\",np.mean(boot_stds_np),\"+/-\",np.std(boot_stds_np))\n"]}, {"cell_type": "markdown", "id": "ea59d3d1", "metadata": {"tags": ["lect_05", "learner"]}, "source": ["While it's not perfect, this method does give us a notion of what level of variability we have. Importantly, for the conventional toy example that we show in teh code above, we sampled a uniform distribution millions of times, whereas for the bootstrap we only sampled the uniform distribution once. This will be critical once we move on to assessing the uncertainty on derived quantities.\n", "\n", "Ok, now that we have done this by hand, let's use the `scipy.stats` tool to make our bootstrapping much easier."]}, {"cell_type": "code", "execution_count": null, "id": "0c00c28f", "metadata": {"tags": ["lect_05", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L21.5-runcell06\n", "\n", "from scipy.stats import bootstrap\n", "import numpy as np\n", "\n", "test_samples = (samples,)\n", "bootstrap_ci = bootstrap(test_samples, np.std, confidence_level=0.68,random_state=1, method='percentile')\n", "print(bootstrap_ci.confidence_interval,(bootstrap_ci.confidence_interval.high-bootstrap_ci.confidence_interval.low)/2.)\n", "print(bootstrap_ci.standard_error)"]}, {"cell_type": "markdown", "id": "bbd16edb", "metadata": {"tags": ["lect_05", "learner"]}, "source": ["Now, the big gain from this approach is that we can start to compute really complicated things that we would not be able to do without sampling events.\n", "\n", "For instance, let's consider a function that is not necessarily differentiable, and see if we can compute the uncertainty on the mean and correlation between the outputs.\n", "\n", "In the block below we will sample a uniform distribution 5000 times from 0 to 100, then we will group these samples into bunches of 10 and take the 10 sort them and output the first and last summed and the 2nd to first and last summed values. Lets look at this output and their correlation. Then lets take the sum of these two values and look at the histogram. \n"]}, {"cell_type": "code", "execution_count": null, "id": "f3383277", "metadata": {"tags": ["lect_05", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L21.5-runcell07\n", "\n", "def func(x):\n", "    x_sort = np.sort(x,axis=1)\n", "    print(x_sort.shape)\n", "    return (np.vstack((x_sort[:,0] + x_sort[:,-1],x_sort[:,1] + x_sort[:,-1] ))).T\n", "\n", "rand_data = np.random.uniform(0,100,5000).reshape(500,10)\n", "out_data = func(rand_data)\n", "plt.plot(out_data[:,0],out_data[:,1],\".\")\n", "plt.show()\n", "print(\"correlation:\",np.corrcoef(out_data[:,0],out_data[:,1]))\n", "\n", "plt.hist(out_data[:,0]+out_data[:,1])"]}, {"cell_type": "markdown", "id": "689d040e", "metadata": {"tags": ["lect_05", "learner"]}, "source": ["Ok, so the above is some complicated mess of a function that is sorting objects and adding them. Computing the uncertainty through error propagation would effectively be impossible. Moreover, sampling events to compute this might not be a possibility. Let's compute the uncertainty on the mean of the sum of the two outputs and the uncertainty on the correlation of the two outputs of this function by bootstrapping. We will boostrap 10k times, and then look at our variation. "]}, {"cell_type": "code", "execution_count": null, "id": "b96a9619", "metadata": {"tags": ["lect_05", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L21.5-runcell08\n", "\n", "boot_sum   = []\n", "boot_corr  = []\n", "for _ in range(10000):\n", "    #boot_sample = np.random.choice(out_data,replace = True, size = 500) # take a random sample each iteration\n", "    boot_sample = out_data[np.random.choice(out_data.shape[0], 500, replace=True)]\n", "    boot_sum.append(np.mean(boot_sample[:,0]+boot_sample[:,1]))\n", "    boot_corr.append(np.corrcoef(boot_sample[:,0],boot_sample[:,1])[1,0])\n", "boot_sum_np = np.array(boot_sum) # transform it into a numpy array for calculation\n", "boot_corr_np = np.array(boot_corr)\n", "print(\"Sum of Boot:\",np.mean(boot_sum_np),\"+/-\",np.std(boot_sum_np),\"-For Comparison sqrt(N) unc-\",np.sqrt(np.mean(boot_sum_np)/500))\n", "print(\"Corr of samples:\",np.mean(boot_corr_np),\"+/-\",np.std(boot_corr_np))\n", "print(boot_sum_np.shape)\n", "\n", "plt.hist(boot_sum_np,density=True)\n", "plt.xlabel(\"$x_{1}+x_{2}$\")\n", "plt.ylabel(\"pdf\")\n", "plt.show()\n", "\n", "plt.hist(boot_corr_np,density=True)\n", "plt.xlabel(\"Corr($x_{1},x_{2}$)\")\n", "plt.ylabel(\"pdf\")\n", "plt.show()"]}, {"cell_type": "markdown", "id": "a2e9e066", "metadata": {"tags": ["lect_05", "learner"]}, "source": ["As you can see we get a nice set of toys that show our intrinsic variation. Moreover, back of the envelope sqrt(N) propagation doesnt necessarily work. This shows how powerful this method is. We aren't propoagating errors, we aren't computing deriviatives, nor ar we generating events. Yet, we still have a knowledge of the uncertainties on our distribution. "]}, {"cell_type": "markdown", "id": "93f17e82", "metadata": {"tags": ["lect_05", "learner"]}, "source": ["<h3>Delete-d Jackknife</h3>\n", "\n", "Another approach to obtaining uncertainty from a fixed dataset is known as the **delete-d jackknife.** In this method, the strategy is to remove a subset of events and recompute the observables. We can then repeat this strategy many times by removing a few events and recomputing everything. The \"Delete-d\" refers to d as the removal of an event. This is sometimes even done as the delete-1 jackknife."]}, {"cell_type": "markdown", "id": "2d0c24fc", "metadata": {"tags": ["md", "learner", "learner_chopped"]}, "source": ["<a name='exercises_22_5'></a>     \n", "\n", "| [Top](#section_22_0) | [Restart Section](#section_22_5) | [Next Section](#section_22_6) |\n"]}, {"cell_type": "markdown", "id": "bc957108", "metadata": {"tags": ["md", "learner", "learner_chopped"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Exercise 21.5.1</span>\n", "\n", "Which of the following statements best describes the purpose of bootstrapping?\n", "\n", "A) Bootstrapping is a technique for selecting a representative subset of the data to improve model training.\\\n", "B) Bootstrapping involves generating random datasets with subsets of the full input dataset in order to estimate the sampling distribution of a statistic.\\\n", "C) Bootstrapping is a method for normalizing the distribution of a dataset to ensure statistical validity.\\\n", "D) Bootstrapping is a process for identifying outliers in a dataset by iteratively removing extreme values.\n", "\n", "\n", "<br>"]}, {"cell_type": "markdown", "id": "5db3600f", "metadata": {"tags": ["md", "learner", "learner_chopped"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Exercise 21.5.2</span>\n", "\n", "Let's test a different distribution and compare the uncertainties on the mean and standard deviation with a boostrapping approach. In the code below, we first sample 1000 data points from a Landau distribution, plot the histogram, and calculate the mean and standard deviation, just for show.\n", "\n", "In the code that you must complete, repeat the direct sampling 50 times to estimate the overall mean and standard deviation, including their uncertainties. Then perform a 10,000-iteration bootstrap on the initial sample `vals` to estimate the mean and standard deviation with their uncertainties, and compare these results to those obtained from multiple sampling.\n", "\n", "Report the mean and uncertainty from direct sampling and the mean and uncertainty with bootstrapping as a list `[mu1, mu1_unc, mu2, mu2_unc]` with the precision of one significant digit.\n", "\n", "<br>"]}, {"cell_type": "code", "execution_count": null, "id": "077abce9", "metadata": {"tags": ["py", "draft", "learner_chopped"]}, "outputs": [], "source": ["#>>>EXERCISE: L21.5.2\n", "\n", "from landaupy import landau\n", "\n", "# Sample the Landau distribution once and plot\n", "vals = landau.sample(10, 5, 1000)\n", "plt.hist(vals, bins=np.arange(0, 100, 2))\n", "plt.xlabel(\"x\")\n", "plt.ylabel(\"N\")\n", "plt.show()\n", "\n", "# Calculate the mean and standard deviation\n", "print(\"One Sample\")\n", "print(\"Mean:\", np.mean(vals), \" Std:\", np.std(vals))\n", "print(\"\")\n", "\n", "# Loop 50 times and compute the mean and uncertainty\n", "# of the sample mean and sample std\n", "samplemean = []\n", "samplestd = []\n", "for i in range(50):\n", "    #sample 1000 pts from a Landau distribution for each run\n", "    #append the lists with the mean and std from each run\n", "    #YOUR CODE HERE\n", "    \n", "print(\"Multiple Samples\")\n", "print(\"Mean from multiple samples:\", np.mean(samplemean), \"+/-\", np.std(samplemean))\n", "print(\"Std from multiple samples:\", np.mean(samplestd), \"+/-\", np.std(samplestd))\n", "print(\"\")\n", "\n", "\n", "# Bootstrap to get the uncertainty on the mean and standard deviation\n", "boot_means = []\n", "boot_stds = []\n", "for _ in range(10000):\n", "    boot_sample = # YOUR CODE HERE: Take a random sample each iteration\n", "    # YOUR CODE HERE: Append the mean to boot_means\n", "    # YOUR CODE HERE: Append the std to boot_stds\n", "\n", "print(\"Bootstrap\")  \n", "print(\"Bootstrap Mean:\", np.mean(boot_means), \"+/-\", np.std(boot_means))\n", "print(\"Bootstrap Std:\", np.mean(boot_stds), \"+/-\", np.std(boot_stds))\n", "\n", "\n"]}, {"cell_type": "markdown", "id": "813af5e1", "metadata": {"tags": ["md", "learner", "learner_chopped"]}, "source": ["<a name='section_22_6'></a>\n", "<hr style=\"height: 1px;\">\n", "\n", "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\">L21.6 Bootstrapping For Neural Networks</h2>  \n", "\n", "| [Top](#section_22_0) | [Previous Section](#section_22_5) |"]}, {"cell_type": "markdown", "id": "e2ded8a9", "metadata": {"tags": ["learner"]}, "source": ["*The material in this section is discussed in the video **<a href=\"https://courses.mitxonline.mit.edu/learn/course/course-v1:MITxT+8.S50.3x+3T2023/block-v1:MITxT+8.S50.3x+3T2023+type@sequential+block@seq_LS21/block-v1:MITxT+8.S50.3x+3T2023+type@vertical+block@vert_LS21_vid1\" target=\"_blank\">HERE</a>.** You are encouraged to watch that video and use this notebook concurrently.*"]}, {"cell_type": "markdown", "id": "f1c8a236", "metadata": {"tags": ["lect_06", "learner"]}, "source": ["<h3>Overview</h3>\n", "\n", "Now that we have gone through the prospects of what it is like to use the bootstrap method, let's see if we can use it to get the uncertainties of our generated sample of proton events. This is where methods like bootstrap can really help us.\n", "\n", "In this section, we will take our simulated proton events and extract uncertainties in the energy shape and profile of the simulation. Once we have done that, we can try doing the same thing with our neural network output.\n", "\n", "To do this, let's look at the profile along the distance of our bins. To make it clear that this is an issue, we can make a plot where we use the standard deviation, and one where we use the standard deviation/$\\sqrt{N}$. Neither of these seem very appropriate.\n"]}, {"cell_type": "code", "execution_count": null, "id": "b39f95a6", "metadata": {"tags": ["lect_06", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L21.6-runcell01\n", "\n", "def makeDataet(iId,ixstep,iestep,iystep):\n", "    print(ixstep.shape,iestep.shape,iystep.shape)\n", "    outdata = np.hstack((ixstep,iystep,iestep))\n", "    outdata = outdata.reshape(1000,3,ixstep.shape[1])\n", "    return outdata\n", "\n", "def profile(iInput):\n", "    profile_out=np.sum(iInput,axis=3)\n", "    return profile_out\n", "\n", "out_profile150=profile(dimage150)\n", "out_profile200=profile(dimage200)\n", "out_profile250=profile(dimage250)\n", "out_profile300=profile(dimage300)\n", "\n", "test_150 = np.mean(out_profile150,axis=0)\n", "test_200 = np.mean(out_profile200,axis=0)\n", "test_250 = np.mean(out_profile250,axis=0)\n", "test_300 = np.mean(out_profile300,axis=0)\n", "\n", "test_150_std = np.std(out_profile150,axis=0)\n", "test_200_std = np.std(out_profile200,axis=0)\n", "test_250_std = np.std(out_profile250,axis=0)\n", "test_300_std = np.std(out_profile300,axis=0)\n", "\n", "test_150_stderr = np.std(out_profile150,axis=0)/np.sqrt(dimage150.shape[0])\n", "test_200_stderr = np.std(out_profile200,axis=0)/np.sqrt(dimage200.shape[0])\n", "test_250_stderr = np.std(out_profile250,axis=0)/np.sqrt(dimage250.shape[0])\n", "test_300_stderr = np.std(out_profile300,axis=0)/np.sqrt(dimage300.shape[0])\n", "\n", "plt.errorbar(np.arange(28),test_150.flatten(),yerr=test_150_std,fmt='o',label='150')\n", "plt.errorbar(np.arange(28),test_200.flatten(),yerr=test_200_std,fmt='o',label='200')\n", "plt.errorbar(np.arange(28),test_250.flatten(),yerr=test_250_std,fmt='o',label='250')\n", "plt.errorbar(np.arange(28),test_300.flatten(),yerr=test_300_std,fmt='o',label='300')\n", "plt.legend()\n", "plt.xlabel('distance(pixel)')\n", "plt.ylabel('Energy(MeV) standard deviation error')\n", "plt.show()\n", "\n", "plt.errorbar(np.arange(28),test_150.flatten(),yerr=test_150_stderr,fmt='o',label='150')\n", "plt.errorbar(np.arange(28),test_200.flatten(),yerr=test_200_stderr,fmt='o',label='200')\n", "plt.errorbar(np.arange(28),test_250.flatten(),yerr=test_250_stderr,fmt='o',label='250')\n", "plt.errorbar(np.arange(28),test_300.flatten(),yerr=test_300_stderr,fmt='o',label='300')\n", "plt.legend()\n", "plt.xlabel('distance(pixel)')\n", "plt.ylabel('Energy(MeV) standard devaition/$\\sqrt{N}$ error')\n", "plt.show()"]}, {"cell_type": "markdown", "id": "13e541ff", "metadata": {"tags": ["lect_06", "learner"]}, "source": ["Ok, now that we have profile, let's go ahead and compute the unceratinties on each bin by bootstrapping, and recomputing the histgram. This way we can can see how off our uncertainties are. \n", "\n", "To avoid making a gazillion plots lets just look at 200 MeV to start with. We will compare it to the equivalent $\\sqrt{N}$ error. \n"]}, {"cell_type": "code", "execution_count": null, "id": "98038f21", "metadata": {"tags": ["lect_06", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L21.6-runcell02\n", "\n", "def profileVar(iData,iNSample):\n", "    boot_profile = []\n", "    for _ in range(iNSample):\n", "        boot_sample = iData[np.random.choice(out_data.shape[0], 1000, replace=True)]\n", "        boot_prof   = np.mean(profile(boot_sample),axis=0)\n", "        boot_profile.append(boot_prof)\n", "    boot_profile = np.array(boot_profile) # transform it into a numpy array for calculation\n", "    return np.mean(boot_profile,axis=0),np.std(boot_profile,axis=0)\n", "\n", "Nsamps=1000\n", "dimage150_boot,dimage150_boot_err = profileVar(dimage150,Nsamps)\n", "dimage200_boot,dimage200_boot_err = profileVar(dimage200,Nsamps)\n", "dimage250_boot,dimage250_boot_err = profileVar(dimage250,Nsamps)\n", "dimage300_boot,dimage300_boot_err = profileVar(dimage300,Nsamps)\n", "\n", "#Uncomment to show all\n", "#plt.errorbar(np.arange(28),dimage150_boot.flatten(),yerr=dimage150_boot_err,fmt='o',label='150 boot')\n", "plt.errorbar(np.arange(28),dimage200_boot.flatten(),yerr=dimage200_boot_err,fmt='o',label='200 boot')\n", "#plt.errorbar(np.arange(28),dimage250_boot.flatten(),yerr=dimage250_boot_err,fmt='o',label='250 boot')\n", "#plt.errorbar(np.arange(28),dimage300_boot.flatten(),yerr=dimage300_boot_err,fmt='o',label='300 boot')\n", "\n", "#Uncomment to show all\n", "#plt.errorbar(np.arange(28),test_150.flatten(),yerr=test_150_stderr,fmt='o',label='150',alpha=0.5)\n", "plt.errorbar(np.arange(28),test_200.flatten(),yerr=test_200_stderr,fmt='o',label='200',alpha=0.5)\n", "#plt.errorbar(np.arange(28),test_250.flatten(),yerr=test_250_stderr,fmt='o',label='250',alpha=0.5)\n", "#plt.errorbar(np.arange(28),test_300.flatten(),yerr=test_300_stderr,fmt='o',label='300',alpha=0.5)\n", "\n", "plt.legend()\n", "plt.xlabel('distance(pixel)')\n", "plt.ylabel('Energy(MeV)')\n", "plt.show()\n", "\n", "print(\"errors from boostrap:\",dimage200_boot_err)\n", "print(\"errors from sqrt(N):\",test_200_stderr)"]}, {"cell_type": "markdown", "id": "6128beb8", "metadata": {"tags": ["lect_06", "learner"]}, "source": ["Here, you can see sqrt(N) and bootstrap give very similar results. However, in some sense this should be expected since our simulation and histogramming are from sampled Monte Carlo events, which should respect poisson uncertainties. \n", "\n", "Now, let's consider a more complicated variable where fluctuations in part of the system can cancel with fluctuations in another part making uncertainties lower than expected.  In partiuclar, what we are going to is loop over the particle shower images and compute the energy profile in the first 3 pixels (0:2) along the x-axis where the particle enters with the maximum energy that the particle deposits in the whole system. \n", "\n", "To look at this variable, we are going to make a few functions. First, we will look just compute the distribution of Emax/Ein (xmaxprofilecheck). Additionally, we will compute the bootstrapped version by computing the mean on a subset of the sample and look at how this mean varies. Lastly, for comparison we will just compute the mean of hte sample, this is a single number, its really the only thing that we can compare our bootstrap too. \n", "\n", "Finally, we will compute the mean and the RMS of the mean for Eout/Ein in two ways. \n", "\n", "1) Boostrap sampling approach<br>\n", "2) Take the mean and standard deviation of our distribution and divide by sqrt(N)\n", "\n", "What we will see is the variation of one of these is much larger than the other. And given the nature of our distributed events, we would expect the boostrap to be better. \n", "\n", "Lets take a look. "]}, {"cell_type": "code", "execution_count": null, "id": "bbcc99b3", "metadata": {"tags": ["lect_06", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L21.6-runcell03\n", "\n", "#Compute our variable\n", "def xmaxprofilecheck(iInput):\n", "    profile_out=np.sum(iInput,axis=2)\n", "    profile_out=np.reshape(profile_out,(iInput.shape[0],28))\n", "    #maxbin=np.argmax(profile_out,axis=1)\n", "    maxbin=np.unravel_index(np.argmax(profile_out, axis=1), profile_out.shape)\n", "    Ein=np.sum(profile_out[:,0:2],axis=1)\n", "    Eout=profile_out[maxbin]#+profile_out[:,maxbin+1]+profile_out[:,maxbin-1]\n", "    ratio=Eout/Ein\n", "    #print(Ein[0],Eout[0],Eout.shape)\n", "    return ratio\n", "\n", "#compute the mean and standard deviation\n", "def xmaxprofile(iInput):\n", "    ratio=xmaxprofilecheck(iInput)\n", "    return np.mean(ratio),np.std(ratio)\n", "\n", "#now bootstracp the profile and compute the meean and standar deviation\n", "def xmaxprofileVar(iData,iNSample):\n", "    boot_profile = []\n", "    for _ in range(iNSample):\n", "        boot_sample          = iData[np.random.choice(out_data.shape[0], 1000, replace=True)]\n", "        boot_prof,boot_std   = xmaxprofile(boot_sample)\n", "        boot_profile.append(boot_prof)\n", "    boot_profile = np.array(boot_profile) # transform it into a numpy array for calculation\n", "    #return np.mean(boot_profile,axis=0),np.std(boot_profile,axis=0)\n", "    return boot_profile\n", "\n", "xtest_150,xtest_150_std=xmaxprofile(dimage150)\n", "xtest_200,xtest_200_std=xmaxprofile(dimage200)\n", "xtest_250,xtest_250_std=xmaxprofile(dimage250)\n", "xtest_300,xtest_300_std=xmaxprofile(dimage300)\n", "print(xtest_200,xtest_200_std)\n", "\n", "xtest_150_stderr = xtest_150_std/np.sqrt(dimage150.shape[0])\n", "xtest_200_stderr = xtest_200_std/np.sqrt(dimage200.shape[0])\n", "xtest_250_stderr = xtest_250_std/np.sqrt(dimage250.shape[0])\n", "xtest_300_stderr = xtest_300_std/np.sqrt(dimage300.shape[0])\n", "\n", "Nsamps=1000\n", "dimage150_boot = xmaxprofileVar(dimage150,Nsamps)\n", "dimage200_boot = xmaxprofileVar(dimage200,Nsamps)\n", "dimage250_boot = xmaxprofileVar(dimage250,Nsamps)\n", "dimage300_boot = xmaxprofileVar(dimage300,Nsamps)\n", "\n", "#plt.hist(dimage150_boot.flatten(),density=True,label='150 boot',alpha=0.5)\n", "plt.hist(dimage200_boot.flatten(),density=True,label='200 bootstrap',alpha=0.5,bins=np.arange(0,15,0.5))\n", "#plt.hist(dimage250_boot.flatten(),density=True,label='250 boot',alpha=0.5,bins=np.arange(0,15,0.5))\n", "#plt.hist(dimage300_boot.flatten(),density=True,label='300 boot',alpha=0.5,bins=np.arange(0,15,0.5))\n", "\n", "#plt.hist(xtest_150.flatten(),label='150',alpha=0.5)\n", "plt.hist(xtest_200.flatten(),label='200 mean(single number)',alpha=0.5,bins=np.arange(0,15,0.5))\n", "#plt.hist(xtest_250.flatten(),label='250',alpha=0.5)\n", "#plt.hist(xtest_300.flatten(),label='300',alpha=0.5)\n", "\n", "\n", "xtest_200_check=xmaxprofilecheck(dimage200)\n", "plt.hist(xtest_200_check.flatten(),density=True,label='200 distribution',alpha=0.5,bins=np.arange(0,15,0.5))\n", "\n", "plt.legend()\n", "plt.xlabel('distance(pixel)')\n", "plt.ylabel('Energy(MeV)')\n", "plt.show()\n", "\n", "def printStats(ilabel,ival,ierr,iboot):\n", "    print(ilabel,\"Val:\",ival,\"+/-\",ierr,\"boot\",np.mean(iboot),\"+/-\",np.std(iboot))\n", "\n", "printStats(\"150 \",xtest_150,xtest_150_stderr,dimage150_boot)\n", "printStats(\"200 \",xtest_200,xtest_200_stderr,dimage200_boot)\n", "printStats(\"250 \",xtest_250,xtest_250_stderr,dimage250_boot)\n", "printStats(\"300 \",xtest_300,xtest_300_stderr,dimage300_boot)"]}, {"cell_type": "markdown", "id": "0c34a6e5", "metadata": {"tags": ["lect_06", "learner"]}, "source": ["Lets digest this. What we have is a mean for 200 MeV poroton (orange). A distribution for the expected mean (blue) from bootstrapping. Finally, we have the actual distribution of the energy variability. What blue is computing is the expected variance, which is quite large. If we were to compute the mean the uncertainty on the mean through normal statistical means, we would find a very small uncertainty (2.47+/-0.027). However, if get the uncertainty from boostrapping we see its 10 times larger. So what is correct? Well likely the bootsrap is more correct. We will do a problem at the end to check this by splitting our sample up and computing the variance. \n", "\n", "Now what is fun is now we can use this bootstrap strategy on our VAE neural network generator, and compute the expected variance on this from generating events. This is a way to get the variation of our neural network generated events. We can then use this to compare our variance with the true dataset to see how accurate itis. \n", "\n", "Now how is this variability, if we generate 1000 images and try to compute it. "]}, {"cell_type": "code", "execution_count": null, "id": "3b057226", "metadata": {"tags": ["lect_06", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L21.6-runcell04\n", "\n", "N=1000\n", "dlimage150 = generate(d,N,cvae_proton_image,1.5)\n", "dlimage200 = generate(d,N,cvae_proton_image,2.0)\n", "dlimage250 = generate(d,N,cvae_proton_image,2.5)\n", "dlimage300 = generate(d,N,cvae_proton_image,3.0)\n", "\n", "Nsamps=1000\n", "dlimage150_boot,dlimage150_boot_err = xmaxprofileVar(dlimage150,Nsamps)\n", "dlimage200_boot,dlimage200_boot_err = xmaxprofileVar(dlimage200,Nsamps)\n", "dlimage250_boot,dlimage250_boot_err = xmaxprofileVar(dlimage250,Nsamps)\n", "dlimage300_boot,dlimage300_boot_err = xmaxprofileVar(dlimage300,Nsamps)\n", "\n", "print(\"err:\",dlimage150_boot_err)\n", "\n", "#plt.errorbar(np.arange(28),dlimage150_boot.flatten(),yerr=dlimage150_boot_err,fmt='o',label='150')\n", "#plt.errorbar(np.arange(28),dlimage200_boot.flatten(),yerr=dlimage200_boot_err,fmt='o',label='200')\n", "#plt.errorbar(np.arange(28),dlimage250_boot.flatten(),yerr=dlimage250_boot_err,fmt='o',label='250')\n", "#plt.errorbar(np.arange(28),dlimage300_boot.flatten(),yerr=dlimage300_boot_err,fmt='o',label='300')\n", "\n", "#plt.errorbar(np.arange(28),test_150.flatten(),yerr=test_150_stderr,fmt='o',label='150',alpha=0.5)\n", "#plt.errorbar(np.arange(28),test_200.flatten(),yerr=test_200_stderr,fmt='o',label='200',alpha=0.5)\n", "#plt.errorbar(np.arange(28),test_250.flatten(),yerr=test_250_stderr,fmt='o',label='250',alpha=0.5)\n", "#plt.errorbar(np.arange(28),test_300.flatten(),yerr=test_300_stderr,fmt='o',label='300',alpha=0.5)\n", "\n", "plt.legend()\n", "plt.xlabel('distance(pixel)')\n", "plt.ylabel('Energy(MeV)')\n", "plt.show()\n"]}, {"cell_type": "code", "execution_count": null, "id": "7be2146f", "metadata": {"tags": ["lect_06", "learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L21.6-runcell05\n", "\n", "N=1000\n", "dlimage150 = generate_base(4,N,proton_vae_image)\n", "dlimage200 = generate(d,N,cvae_proton_image,2.0)\n", "#dlimage250 = generate(d,N,cvae_proton_image,2.5)\n", "#dlimage300 = generate(d,N,cvae_proton_image,3.0)\n", "\n", "Nsamps=1000\n", "xdlimage150_boot = xmaxprofileVar(dlimage150,Nsamps)\n", "xdlimage200_boot = xmaxprofileVar(dlimage200,Nsamps)\n", "#xdlimage250_boot = xmaxprofileVar(dlimage250,Nsamps)\n", "#xdlimage300_boot = xmaxprofileVar(dlimage300,Nsamps)\n", "\n", "print(\"err:\",dlimage150_boot_err)\n", "\n", "#plt.hist(xdlimage150_boot.flatten(),density=True,label='150 NN',alpha=0.5)\n", "#plt.hist(dimage150_boot.flatten(),density=True,label='150 MC',alpha=0.5)\n", "\n", "plt.hist(xdlimage200_boot.flatten(),density=True,label='200 NN',alpha=0.5)\n", "plt.hist(dimage200_boot.flatten(),density=True,label='200 MC',alpha=0.5)\n", "\n", "#plt.hist(xdlimage200_boot.flatten(),density=True,label='200',alpha=0.5)\n", "#plt.hist(xdlimage250_boot.flatten(),density=True,label='250',alpha=0.5)\n", "#plt.hist(xdlimage300_boot.flatten(),density=True,label='300',alpha=0.5)\n", "\n", "plt.hist(xtest_150.flatten(),label='150-avg',alpha=0.5)\n", "plt.hist(xtest_200.flatten(),label='200',alpha=0.5)\n", "plt.hist(xtest_250.flatten(),label='250',alpha=0.5)\n", "plt.hist(xtest_300.flatten(),label='300',alpha=0.5)\n", "\n", "plt.legend()\n", "plt.xlabel('distance(pixel)')\n", "plt.ylabel('Energy(MeV)')\n", "plt.show()\n"]}], "metadata": {"celltoolbar": "Tags", "kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}